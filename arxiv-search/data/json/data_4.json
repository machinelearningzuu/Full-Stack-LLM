{"url": "http://arxiv.org/pdf/2311.05591v1", "title": "Accuracy of a Vision-Language Model on Challenging Medical Cases", "text": "Accuracy\nof\na\nVision-Language\nModel\non \nChallenging\nMedical\nCases\nThomas\nBuckley\n1\n,\nJames\nA.\nDiao,\nB.S.\n1\n,\nAdam\nRodman,\nM.D.\n2\n,\nand\nArjun\nK.\nManrai,\nPh.D.\n1\n*\n1\nDepartment\nof\nBiomedical\nInformatics,\nHarvard\nMedical\nSchool,\nBoston,\nMA\n2\nDepartment\nof\nMedicine,\nBeth\nIsrael\nDeaconess\nMedical\nCenter,\nBoston,\nMA\n*Correspondence:\nArjun\nK.\nManrai,\nPh.D.\nDepartment\nof\nBiomedical\nInformatics,\nHarvard\nMedical\nSchool\n10\nShattuck\nSt.,\nBoston,\nMA,\n02115\nArjun_Manrai@hms.harvard.edu\n1 ABSTRACT\nBackground\n:\nGeneral-purpose\nlarge\nlanguage\nmodels\nthat\nutilize\nboth\ntext\nand\nimages\nhave\nnot\nbeen\nevaluated\non\na\ndiverse\narray\nof\nchallenging\nmedical\ncases.\nMethods\n:\nUsing\n934\ncases\nfrom\nthe\nNEJM\nImage\nChallenge\npublished\nbetween\n2005\nand\n2023,\nwe\nevaluated\nthe\naccuracy\nof\nthe\nrecently\nreleased\nGenerative\nPre-trained\nTransformer\n4\nwith\nVision\nmodel\n(GPT-4V)\ncompared\nto\nhuman\nrespondents\noverall\nand\nstratified\nby\nquestion\ndifficulty,\nimage\ntype,\nand\nskin\ntone.\nWe\nfurther\nconducted\na\nphysician\nevaluation\nof\nGPT-4V\non\n69\nNEJM\nclinicopathological\nconferences\n(CPCs).\nAnalyses\nwere\nconducted\nfor\nmodels\nutilizing\ntext\nalone,\nimages\nalone,\nand\nboth\ntext\nand\nimages.\nResults\n:\nGPT-4V\nachieved\nan\noverall\naccuracy\nof\n61%\n(95%\nCI,\n58\u201364%)\ncompared\nto\n49%\n(95%\nCI,\n49\u201350%)\nfor\nhumans.\nGPT-4V\noutperformed\nhumans\nat\nall\nlevels\nof\ndifficulty\nand\ndisagreement,\nskin\ntones,\nand\nimage\ntypes;\nthe\nexception\nwas\nradiographic\nimages,\nwhere\nperformance\nwas\nequivalent\nbetween\nGPT-4V\nand\nhuman\nrespondents.\nLonger,\nmore\ninformative\ncaptions\nwere\nassociated\nwith\nimproved\nperformance\nfor\nGPT-4V\nbut\nsimilar\nperformance\nfor\nhuman\nrespondents.\nGPT-4V\nincluded\nthe\ncorrect\ndiagnosis\nin\nits\ndifferential\nfor\n80%\n(95%\nCI,\n68\u201388%)\nof\nCPCs\nwhen\nusing\ntext\nalone,\ncompared\nto\n58%\n(95%\nCI,\n45\u201370%)\nof\nCPCs\nwhen\nusing\nboth\nimages\nand\ntext.\nConclusions\n:\nGPT-4V\noutperformed\nhuman\nrespondents\non\nchallenging\nmedical\ncases\nand\nwas\nable\nto\nsynthesize\ninformation\nfrom\nboth\nimages\nand\ntext,\nbut\nperformance\ndeteriorated\nwhen\nimages\nwere\nadded\nto\nhighly\ninformative\ntext.\nOverall,\nour\nresults\nsuggest\nthat\nmultimodal\nAI\nmodels\nmay\nbe\nuseful\nin\nmedical\ndiagnostic\nreasoning\nbut\nthat\ntheir\naccuracy\nmay\ndepend\nheavily\non\ncontext.\n2 INTRODUCTION\nClinical\nreasoning\nis\na\ncomplex\ncognitive\ntask\nthat\nincludes\nthe\nintegration\nof\nmultiple\ntypes\nof\nclinical\ndata.\n1\nMuch\nof\nthis\ndata\ncomes\nfrom\nthe\npatient,\nincluding\nthe\nchief\nconcern\nand\nhistory\nof\npresent\nillness\nas\nwell\nas\nthe\nphysical\nexamination.\nHowever,\nincreasingly\nthis\ninformation\nis\nstored\nin\nelectronic\nformat,\nsuch\nas\nprogress\nnotes\nand\ndischarge\nsummaries,\nclinical\nimages,\nand\npatient-provider\ncommunications.\nThis\ninformation\nis\noften\npoorly\norganized,\nlengthy,\nand\nduplicative.\n2\nExpert\nclinicians\nquery,\norganize,\nand\ninterpret\nsignals\nfrom\nthis\ncomplex\nmixture\nof\ndata\nto\nconstruct\na\ncomprehensive\nclinical\npicture\nof\nthe\npatient.\nWith\nincreasing\ncomplexity\nof\nclinical\ninformation,\nartificial\nintelligence\n(AI)\napplications\nin\nmedicine\nhave\nshown\npromise\nto\nassist\nwith\nclinical\nreasoning\ntasks.\nTo\ndate,\nmost\nAI\nmodels\nfocus\non\na\nspecific\nclinical\ntask\nusing\na\nsingle\ndata\nmodality;\nfor\nexample,\ndetecting\ndiabetic\nretinopathy\nfrom\nretinal\nfundus\nphotographs.\n3,4\nAt\nthe\nsame\ntime,\nlarge\nlanguage\nmodels\n(LLMs)\nlike\nGenerative\nPre-trained\nTransformer\n4\n(GPT-4)\n5,6\nhave\ndemonstrated\nstrong\nperformance\non\nan\narray\nof\ntext-based\ntasks\nincluding\nanswering\nmedical\nlicensing\nexam\nquestions,\n7\nwriting\nempathetic\nresponses\nto\npatient\nqueries,\n8\nand\nsolving\nchallenging\ndiagnostic\ncases.\n9\nJust\nas\nhuman\nexperts\ncan\nbetter\ninterpret\nimage\nstudies\nwhen\nprovided\nclinical\ncontext,\nmultimodal\nAI\nmodels\nthat\nutilize\nboth\nmedical\nimages\nand\ntext\nmay\nexhibit\nsuperior\ngeneral\ndiagnostic\nperformance\ncompared\nto\nunimodal\nsystems\nthat\nutilize\nimages\nor\ntext\nalone.\nHowever,\nthere\nis\nlimited\nevidence\nof\nmultimodal\nreasoning\non\na\ngeneral\ncollection\nof\nchallenging\nmedical\ncases;\nthis\nmay\nbe\nattributable\nto\nboth\nlimitations\nin\ndata\nbenchmarks\nused\nand\nAI\nmodel\navailability.\nHere,\nwe\nevaluated\nthe\naccuracy\nof\nthe\nnew\nGPT-4\nwith\nvision\nmodel\n(GPT-4V),\n10\nan\nAI\nvision-language\nmodel\nreleased\non\nSeptember\n25,\n2023,\non\n934\ncases\nfrom\nthe\nNew\nEngland\nJournal\nof\nMedicine\n(\nNEJM\n)\nImage\nChallenge\nspanning\n2005\nto\n2023.\n11\nWe\nfurther\nanalyzed\nthe\nAI\nmodel\u2019s\nability\nto\nuse\nimages\nin\n69\ncases\nfrom\nthe\nNEJM\nclinicopathological\nconferences,\n3 which\npresent\ncomplex\nmedical\nscenarios\nculminating\nin\ndefinitive\npathological\ndiagnoses.\nGPT-4V\ninteracts\nwith\ntext,\nimages,\nor\ntext\nand\nimages\ntogether.\nThe\nclinical\ncases\ninclude\npaired\ntext\nprompts\nthat\nvary\nconsiderably\nin\ntheir\nlength\nand\ninformation\ncontent,\nenabling\nfine-grained\nanalysis\nof\nrelative\ncontributions\nto\naccuracy\nfrom\nimages\nthemselves\nversus\nthe\ntext\nthat\naccompany\nthem.\nWe\ncompare\nGPT-4V\u2019s\naccuracy\nto\nhuman\nrespondents\nacross\ncase\ndifficulty\nand\ndisagreement\nlevels,\nimage\ntypes,\nclinical\ndomains,\nand\nskin\ntones,\nand\nfurther\nanalyze\ncommon\nerrors\nby\nboth\nhumans\nand\nthe\nAI\nmodel\nto\nunderstand\nthe\npotential\nnear-term\nrelevance\nof\nmultimodal\nAI\nin\nmedical\ndiagnosis.\n4 METHODS\nImage\nChallenge\nCases\nand\nClinicopathological\nConferences\nWe\nretrieved\n936\ncases\nfrom\nthe\nNEJM\nImage\nChallenge\n11\npublished\nbetween\n2005\nand\nOctober\n12,\n2023.\nEach\ncase\nconsists\nof\na\nmedical\nimage\nand\nassociated\nprompt\nquestion\n(e.g.,\n\u201cWhat\nis\nthe\nmost\nlikely\ndiagnosis?\u201d),\nfive\nmultiple-choice\noptions,\nand\na\nhidden\ncorrect\nanswer.\nMany\ncases\nadditionally\nprovide\ntext\ncaptions\nwith\nrelevant\nclinical\ncontext\nor\nother\nbackground\ninformation.\nRespondents,\nlikely\ncomprising\nphysicians\nand\nmedical\ntrainees,\nsubmit\nanswers\nthrough\nthe\nNEJM\nwebsite\nand\nmobile\napp;\nwe\nobtained\nthe\ndistribution\nof\nresponses\nfor\neach\ncase.\nThe\nimages\nincluded\nradiographic\nimages,\nnatural\nand\ndermatoscopic\nskin\nimages,\nelectrocardiograms,\nhistopathology\nimages,\nendoscopy\nimages,\nand\nophthalmoscopy\nimages.\nThe\nNEJM\nclinicopathological\nconferences,\nalso\nknown\nas\nthe\nCase\nRecords\nof\nthe\nMassachusetts\nGeneral\nHospital,\nare\nchallenging\ncases\nthat\nbegin\nwith\nan\ninitial\ncase\npresentation\ncomprising\nboth\ntext\nand\nimages.\nAn\nexpert\nphysician\nis\nasked\nto\nprovide\nan\ninitial\ndifferential\ndiagnosis\nand\nmost\nlikely\ndiagnosis,\nfollowed\nby\na\nreview\nof\nadditional\ntesting\nand\nthe\nfinal\ndiagnosis.\nWe\nretrieved\ntext\nand\nimages\nfrom\nthe\n\u201cPresentation\nof\nCase\u201d\nsection\nof\n80\nclinicopathological\ncases\npublished\nbetween\nJanuary\n2021\nand\nDecember\n2022,\nand\napplied\nthe\nsame\nexclusion\ncriteria\nused\nin\na\nprior\nstudy\nthat\nused\nGPT-4\non\ntext\nonly.\n9\nWe\nexcluded\n4\ncases\nthat\nwere\nnot\ndiagnostic\ndilemmas,\n6\ncases\nthat\nwere\ntoo\nlong\nto\nrun\nin\na\nsingle\nprompt,\nand\none\ncase\nthat\nGPT-4V\nrefused\nto\nrun\nbased\non\ncontent,\nleaving\n69\ntotal\ncases.\nGPT-4V\nExperiments\nAll\nimage\nchallenge\ncases\nwere\nrun\nthrough\nthe\nChatGPT\nweb\ninterface\nusing\nthe\nGPT-4V\nmodel\nduring\nOctober\n2023.\nA\nnew\nsession\nwas\nused\nfor\neach\nquestion\nto\nprevent\ninformation\nleakage\nfrom\nprevious\nqueries.\nA\nprefix\nprompt\ndescribing\nthe\nformat\nof\nthe\nimage\nchallenge\nand\ninstructing\nthe\nmodel\nto\nact\nas\na\nmedical\nexpert\nwas\nprepended\nto\neach\nquestion\n5 (\nSupplementary\nAppendix\n).\nEvaluation\nwas\nperformed\nby\nprompting\nGPT-4\nto\nscore\nthe\nGPT-4V\nresponse\nto\neach\nquestion\nby\ncomparing\na\nprediction\nto\nthe\nreference\nanswer\nand\nproviding\nthree\nscoring\noptions:\ncorrect,\nincorrect,\nor\nrefused\n(Supplementary\nAppendix).\nManual\ninspection\nof\nthe\nscoring\nwas\nperformed\nfor\nhalf\nof\nthe\nmultimodal\ntrial\ncases\nto\nensure\naccuracy.\nSince\nGPT-4V\nis\npretrained\non\nmassive\namounts\nof\ndata\nincluding\nscraped\nweb\npages,\nmemorization\nof\nleaked\ncases\ncould\naffect\nperformance.\nThe\ntraining\nof\nGPT-4V\nended\nin\n2022.\n6\nWe\ntherefore\nperformed\na\nsensitivity\nanalysis\nand\nmeasured\nthe\naccuracy\non\ncases\nin\n2023\nalone\nto\ncompare\nto\nits\nperformance\nin\nearlier\nyears.\nTo\nstudy\nmultimodality,\nwe\nevaluated\nmodel\nperformance\non\ncases\nwith\nonly\nthe\nimage\nincluded,\nonly\nthe\ntext\nincluded,\nand\nboth\nincluded;\nthe\nprefix\nprompt\nwas\nadjusted\naccordingly\n(Supplementary\nAppendix).\nWe\nthen\nstratified\nperformance\nby\ndecile\nof\nquestion\nword\ncount.\nWe\nfurther\ncompared\nthe\naccuracy\nof\nGPT-4V\nby\nimage\ntype\nand\nskin\ntone\nusing\na\nprior\nset\nof\nannotations\nfrom\nthe\nNEJM\nImage\nChallenge.\n12\nAnnotations\nwere\navailable\nfor\n764\ncases.\nSince\nthe\nNEJM\nImage\nChallenge\ncovers\na\nbroad\nspectrum\nof\nspecialities,\nwe\nlimited\nevaluation\nto\nimage\ntypes\nwith\nat\nleast\n30\ncases,\nwhich\nincluded:\ncutaneous-subcutaneous\n(311\ncases),\nradiology\n(219\ncases),\noral-external\n(62\ncases),\nand\nocular-external\n(43\ncases).\nRemaining\nannotated\nimages\nwere\ncategorized\nas\nother\n(129\ncases).\nTo\nelicit\nreasoning\nfor\ncase\nstudy\nexamples,\nwe\nused\nchain-of-thought\n(CoT)\nprompting\nwhich\nadds\n\u201cLet\u2019s\nthink\nstep\nby\nstep\u201d\nto\nthe\nend\nof\nthe\nprompt.\n13\nFor\nthe\nNEJM\nclinicopathological\nconferences,\nwe\nprovided\nthe\ntext\nof\nthe\ncase\nup\nto\nbut\nnot\nincluding\nthe\ndiscussant\u2019s\ninitial\nresponse\nand\ndifferential\ndiagnosis.\nImage\ncaptions\nand\ntables\nwere\nnot\nincluded.\nThe\nsame\nprompt\nwas\nused\nfor\nboth\ntext-only\nand\nmultimodal\n(text\nand\nimage)\ntrials.\nOur\nprimary\noutcome\nwas\nwhether\nor\nnot\nthe\nfinal\ndiagnosis\nappeared\nin\nthe\ndifferential.\nSecondary\noutcomes\nincluded\nhaving\nthe\ncorrect\ndiagnosis\nlisted\nas\nthe\ntop\ndiagnosis\non\nthe\ndifferential,\nthe\nlength\nof\nthe\ndifferential,\nand\nthe\nquality\nof\nthe\ndifferential\n6 scored\nusing\na\npreviously-published\nordinal\n5-point\nrating\nscale\nthat\ndescribes\nboth\naccuracy\nand\nusefulness,\nwhere\na\n5\nis\ngiven\nfor\nhaving\nthe\nexact\ndiagnosis\non\nthe\ndifferential,\nand\na\n0\nis\ngiven\nwhen\nno\ndiagnoses\nwere\nclose.\n14\nA\nphysician\n(A.R.)\ngraded\nboth\nmultimodal\nGPT-4V\nand\nGPT-4V\n(Text\nOnly)\noutputs\nfor\nall\nNEJM\nclinicopathological\nconferences.\nAdditionally,\nover\nthe\ntwo\nweeks\nwe\nran\nthese\nexperiments,\nwe\nnoticed\na\nchange\nin\nthe\ncontent\nmoderation\npolicy\non\nChatGPT.\nAfter\nthe\nsecond\nweek,\n2\ncases\nwere\nno\nlonger\naccepted\nby\nthe\nChatGPT\nweb\ninterface\n(cases\ndated\n05-19-2016\nand\n11-03-2011),\nreducing\nthe\ninitial\nset\nof\n936\nimages\nto\n934\nimages.\nThis\nis\nlikely\ndue\nto\nadded\nfilters\npreventing\nimages\nthat\nare\nassumed\nto\nbe\nsexually\nexplicit.\nStatistical\nAnalysis\nFor\nhuman\naccuracy\non\na\nset\nof\ncases,\nwe\ncomputed\nthe\nmean\nof\nproportion\ncorrect\nfor\neach\nquestion.\n95%\nconfidence\nintervals\nfor\nhuman\naccuracy\nwere\ncomputed\nusing\nthe\nt-distribution.\nGPT\naccuracy\non\na\nset\nof\ncases\nwas\ncomputed\nas\nthe\nproportion\ncorrect\nwith\n95%\nconfidence\nintervals\ncomputed\nusing\nexact\nClopper-Pearson\nintervals.\nAbsolute\ndifferences\nwere\ncomputed\nusing\nan\nunpaired\nt-test\nwhile\nrelative\ndifferences\nwere\ncomputed\nusing\nbootstrapping\nwith\n5000\nreplicates.\nP-values\nwere\nadjusted\nfor\nmultiple\ntesting\nusing\nthe\nHolm\u2013Bonferroni\nmethod.\nStatistical\nanalyses\nwere\nperformed\nin\nR\nversion\n4.3.0.\nThe\nHarvard\nMedical\nSchool\nInstitutional\nReview\nBoard\n(IRB)\ndetermined\nthat\nthis\nstudy\ndoes\nnot\nrequire\nIRB\noversight.\n7 RESULTS\nAccuracy\nof\na\nMultimodal\nLLM\non\nChallenging\nMedical\nCases\nCompared\nto\nHumans\nGPT-4V\nachieved\nan\noverall\naccuracy\nof\n61%\n(95%\nCI,\n58%\nto\n64%)\nacross\nthe\n934\nimage\nchallenge\ncases,\ncompared\nto\nan\noverall\naccuracy\nof\n49%\n(95%\nCI,\n49%\nto\n50%)\nfor\nhuman\nrespondents\n(Table\n1).\nWe\nranked\ncases\nby\ntheir\nlevel\nof\ndifficulty\nusing\nhuman\nrespondent\naccuracy\nand\ngrouped\nthem\ninto\ntertiles\nrepresenting\neasy,\nmedium,\nand\nhard\ncases.\nGPT-4V\noutperformed\nhuman\nrespondents\nat\nevery\nlevel\nof\ndifficulty,\nranging\nfrom\n72%\n(95%\nCI,\n66%\nto\n77%)\non\neasy\ncases\nto\n44%\n(95%\nCI,\n39%\nto\n50%)\non\nhard\ncases.\nSimilarly,\nwe\nanalyzed\nperformance\nof\nGPT-4V\nand\nhuman\nrespondents\nby\nthe\nlevel\nof\ndisagreement\namongst\nhuman\nrespondents\non\nquestions,\nmeasured\nusing\nShannon\nentropy.\nHuman\nagreement\nwas\nassociated\nwith\nimproved\nperformance\nfor\nboth\nhuman\nrespondents\nand\nGPT-4V,\nwith\nGPT-4V\nagain\noutperforming\nhuman\nrespondents\nat\neach\nlevel.\nBecause\npre-training\ndata\nfor\nGPT-4V\nwent\nthrough\n2022\n10\nand\nmay\ninclude\npreviously\npublished\nNEJM\nImage\nChallenge\ncases,\nwe\ncompared\nthe\n41\ncases\npublished\nin\n2023\nwith\nthe\n893\ncases\npublished\nbetween\n2005\nand\n2022,\nshown\nin\nTable\n1.\nGPT-4V\nhad\nan\naccuracy\nof\n76%\n(95%\nCI,\n60%\nto\n88%)\nin\n2023\nand\n60%\n(95%\nCI,\n57%\nto\n64%)\nin\n2005\nto\n2022.\nRespondents\nhad\nan\naccuracy\nof\n51%\n(95%\nCI,\n47%\nto\n54%)\nin\n2023\nand\n49%\n(95%\nCI,\n49%\nto\n50%)\nin\n2005\nto\n2022.\nEvidence\nof\nMultimodal\nReasoning\nOver\nText,\nImages,\nand\nBoth\nTogether\nThe\nevolving\nformat\nof\nthe\nNEJM\nImage\nChallenge,\nincluding\nvarying\nlength\nand\ninformation\ncontent\nof\naccompanying\ntext\ncaptions,\nallowed\nfor\na\nunique\nanalysis\nof\nthe\nmultimodal\nreasoning\ncapabilities\nof\nGPT-4V.\nSpecifically,\nwhile\nevery\ncase\nincludes\nan\nimage,\nthe\ncases\nvary\nsubstantially\nin\nthe\nlength\nand\ninformation\ncontent\nof\nthe\naccompanying\ntextual\ndescription.\nSeveral\nhundred\ncases\ncontain\nonly\nthe\nfour-word\ntext\nprompt\n\u201cWhat\nis\nthe\ndiagnosis?\u201d\nwhile\n8 other\ntext\ndescriptions\ncontain\ninformation\non\nnotable\nimage\nfeatures,\nclinical\nand\nsocial\nhistory,\nand\nresults\nof\nother\nclinical\ntests.\nFor\neach\ncase,\nwe\ncompared\nthe\nperformance\nof\nmultimodal\n\u201cGPT-4V\u201d\n(using\nboth\nimage\nand\ntext\ninputs)\nto\n\u201cGPT-4V\n(Text\nOnly)\u201d\nwhere\nthe\nmodel\nis\nprovided\nonly\nthe\ncase\ntext\ndescription,\nand\n\u201cGPT-4V\n(Image\nOnly)\u201d\nwhere\nthe\nmodel\nis\nprovided\nonly\nthe\nimage.\nWe\nstratified\nperformance\nby\nthe\ndecile\nof\nthe\nquestion\nword\ncount\nas\na\nproxy\nfor\nthe\ninformation\ncontent\nin\nthe\naccompanying\ntext\ndescription\n(Figure\n1A).\nAt\none\nextreme\nof\nlow\nword\ncount,\nwhen\nthe\ntext\nis\nuninformative\n(e.g.\n\u201cWhat\nis\nthe\ndiagnosis?\u201d),\nGPT-4V\n(Text\nOnly)\noften\nrefuses\nto\nanswer\nthe\nquestion\n(Supplemental\nTable\n1A)\nand\nmultimodal\nGPT-4V\u2019s\nperformance\nmatched\nthat\nof\nGPT-4V\n(Image\nOnly),\noutperformed\nrandom\nguessing,\nand\nunderperformed\nhuman\nrespondents.\nAt\nthe\nother\nextreme,\nwhen\ntext\nis\nhighly\ninformative,\nGPT-4V\n(Text\nOnly)\nperforms\nequally\nwell\nas\nmultimodal\nGPT-4V,\nand\nboth\nsubstantially\noutperform\nhuman\nrespondents\nand\nGPT-4V\n(Image\nOnly).\nBetween\nthese\nextremes,\nmultimodal\nGPT-4V\noutperforms\nboth\nof\nits\ntext-only\nand\nimage-only\ncounterparts,\nand\nstarts\nperforming\nbetter\nthan\nhuman\nrespondents\nafter\nthe\nthird\ndecile\nof\nquestion\nword\ncount.\nUnlike\nGPT-4V,\nhuman\nrespondents\ndo\nnot\nperform\nbetter\nwith\nlonger\ntext\ncaptions,\nsuggesting\nthat\nthey\ndo\nnot\nrely\nmuch\non\nthe\ntext\ndescriptions\n(Figure\n1A).\nOver\nall\n934\ncases,\nperformance\nwas\nhighest\nfor\nGPT-4V,\nfollowed\nby\nGPT-4V\n(Text\nOnly)\nand\nhuman\nrespondents,\nand\nthen\nby\nGPT-4V\n(Image\nOnly),\nas\nshown\nin\nFigure\n1B.\nAll\nGPT-4V\nvariants\nand\nhuman\nrespondents\nperformed\nsubstantially\nbetter\nthan\nrandom\nguesses.\nAccuracy\nby\nImage\nType\nand\nby\nSkin\nColor\nCases\npublished\nbetween\nOctober\n2005\nto\nJuly\n2020\nwere\npreviously\nlabeled\nby\nimage\ntype,\nincluding\nnatural\nand\ndermatoscopic\nimages\nof\nskin\ndisease,\nradiographic\nimages,\nexternal\nocular\nimages,\nand\nexternal\noral\nimages.\n12\nGPT-4V\noutperformed\nhuman\nrespondents\nin\neach\ncategory.\nThe\none\nexception\nwas\nradiographic\nimages,\non\nwhich\nGPT-4V\nhad\nsimilar\naccuracy\n9 to\nhuman\nrespondents.\nOn\nbalance,\nnatural\nimages,\nincluding\nthose\nof\nskin,\neyes,\nand\nmouth,\nwere\nassociated\nwith\nthe\nhighest\ndiagnostic\naccuracy.\nOf\nthe\n767\ncases\npublished\nbetween\nOctober\n13,\n2005\nand\nJuly\n9,\n2020,\n420\nindexed\ncases\nincluded\nimages\ncontaining\nskin\nwith\nidentifiable\nskin\ntone.\nEach\nof\nthese\nimages\nwas\ngiven\na\nFitzpatrick\nskin\ntype\nrating\nby\na\nboard-certified\ndermatologist\nin\na\nprior\nstudy.\n12\nWe\nanalyzed\nGPT-4V\nand\nhuman\nrespondent\nperformance\nby\nskin\ntype,\ncategorized\ninto\n\u201clight\u201d\n(1-2),\n\u201cintermediate\u201d\n(3-4),\nand\n\u201cdark\u201d\n(5-6).\nGPT-4V\nperformed\nbetter\nthan\nhuman\nrespondents\nacross\nall\nskin\ntones\nand\nwe\nfound\nthat\nneither\nhumans\nnor\nGPT-4V\nexhibited\ndifferences\nin\naccuracy\nby\nskin\ntone.\nMultimodal\nReasoning\nExplanations\nby\nGPT-4V\nGPT-4V,\nGPT-4V\n(Image\nOnly),\nand\nGPT-4V\n(Text\nOnly)\ndemonstrated\nvarying\ndegrees\nof\nclinical\nreasoning\nunder\nuncertainty,\nwhich\nwere\nelucidated\nby\nexamining\nsuccess\nand\nfailure\nmodes\n(Figure\n3).\nWhen\nperformed\ncorrectly,\ntext-based\nreasoning\nallowed\nGPT-4V\nto\nanswer\ndifficult\nquestions\nthat\nthe\nmajority\nof\nrespondents\nanswered\nincorrectly.\nFor\nexample,\nin\na\ncase\nof\ndiagnosing\nnon-pruritic,\nnon-hypoethestic\nlesions\nin\na\nrecent\nimmigrant\nfrom\nPakistan,\nGPT-4V\n(Text\nOnly)\ninferred\nthe\ncorrect\nanswer\nbased\non\nprevalence\nin\nPakistan,\ncorrectly\nnoting\nthat\nhypoesthesia\nis\ncommon\nbut\nnot\nuniversally\npresent\nin\nleprosy\n(Figure\n3A).\nGPT-4V\n(Multimodal)\nagreed,\nwhile\nGPT-4V\n(Image\nOnly)\nincorrectly\nclassified\nthe\nlesions\nas\nscrofula.\nIn\nanother\ncase\nof\ndiagnosing\na\nrash\nunder\nultraviolet\nlight,\nall\nGPT-4V\nmodels\ncorrectly\nanswered\n\u201cerythrasma\u201d\n(Figure\n3B).\nThe\nmultimodal\nGPT-4V\nmodel\ncorrectly\nnotes\nthat\nthese\nlesions\nfluoresce\ncoral\nred\nunder\nultraviolet\nlight.\nThe\nGPT-4V\n(Text\nOnly)\nmodel\ncorrectly\nanswered\nwith\nthe\nfollowing\nreasoning:\n\u201cthe\ndiagnosis\nthat\ncan\nbe\nspecifically\nidentified\nby\nultraviolet\nlight\n(Wood's\nlamp)\nis\n\u2018Erythrasma\u2019.\u201d\nThis\nindicates\nboth\nthe\nability\nof\nvision-language\nmodels\nto\nprovide\nbest\nguess\nanswers\nto\nmultiple-choice\nquestions\nunder\nlimited\ninformation,\nbut\nalso\nits\ntendency\nto\nprovide\nanswers\neven\nwhen\na\ndiagnosis\ncannot\nbe\ndetermined\nfrom\nthe\ngiven\ndata.\n10 GPT-4V\nalso\nexhibited\nseveral\nimportant\nfailure\nmodes.\nThese\ninclude\nthe\ninability\nto\nperform\ncorrect\nvisual\nassessments\nof\nkey\nimage\nfeatures,\nas\nobserved\nin\nthe\ncase\non\npectus\nexcavatum\n(Figure\n3C),\nwhere\n79%\nof\nhuman\nrespondents\nidentified\nthe\ncorrect\ndiagnosis.\nIntegrating\nImages\nwith\nText\nin\nClinicopathological\nConferences\nMultimodal\nGPT-4V\nwas\nevaluated\non\n69\nNEJM\nclinicopathological\nconferences\npublished\nbetween\nJanuary\n2021\nand\nDecember\n2022\nto\ncompare\nwith\na\nprior\nstudy\nof\nunimodal\nGPT-4\nthat\nused\ncase\ntext\nonly.\n9\nAs\nshown\nin\nFigure\n4,\nphysician-assessed\nperformance\nshowed\nthat\nthe\nfinal\ndiagnosis\nwas\nincluded\nin\nthe\ndifferential\nin\n40\ncases\n(58%,\n95%\nCI,\n45-70%)\nwhen\nusing\nGPT-4V\nand\n55\ncases\n(80%,\n95%\nCI,\n68-88%)\nwhen\nusing\nGPT-4V\n(Text\nOnly).\nMultimodal\nGPT-4V\nassigned\nthe\ncorrect\ndiagnosis\nin\n21\ncases\n(30%,\n95%\nCI,\n20-43%)\nwhile\nGPT-4V\n(Text\nOnly)\nassigned\nthe\ncorrect\ndiagnosis\nin\n22\ncases\n(32%,\n95%\nCI,\n21-44%).\nThe\nmean\nquality\nscore\nwas\n4.2\n(SD\n1.1)\nfor\nGPT-4V\nand\n4.7\n(SD\n0.7)\nfor\nGPT-4V\n(Text\nOnly).\nQualitative\ndifferences\nbetween\nthe\ntwo\nmodels\nare\nshown\nin\nexamples\nin\nSupplemental\nTable\n2.\nGPT-4V\n(Text\nOnly)\nincluded\nmore\nspecific\ndiagnoses\nwhereas\nmultimodal\nGPT-4V\nincluded\nmore\ngeneral\ndiagnoses\nlike\n\u201cinflammatory\nconditions\u201d\nor\n\u201cmetastatic\ncancer.\u201d\nGPT-4V\nalso\ndemonstrated\nless\ncausal\nlanguage,\nwhile\nGPT-4V\n(Text\nOnly)\ntypically\nincluded\nmore\ncomplex\ndiagnoses\nsuch\nas\n\u201cmetastatic\ndisease\nin\nthe\nlung\ncausing\nthe\ncavitary\nlesion.\u201d\n11 DISCUSSION\nGPT-4V\noutperformed\nhuman\nrespondents\nin\nthe\nNEJM\nImage\nChallenge\nacross\nall\nlevels\nof\ncase\ndifficulty\nand\ndisagreement,\nskin\ntones,\nand\nimage\ntypes.\nThe\none\nexception\nwas\nfor\nradiographic\nimages,\nwhere\nthe\nAI\nmodel\nmatched\nhuman\nrespondents.\nGPT-4V\nanswered\nquestions\nusing\ntext\ndescriptions\nalone,\nimages\nalone,\nor\nboth\nmodalities\ntogether,\nin\nmany\ncases\nproviding\ncoherent\nexplanations\nfor\nits\nreasoning.\nThe\nperformance\nof\nGPT-4V\nincreased\nwith\nthe\namount\nof\ninformative\ntext,\nwhereas\nthe\nperformance\nof\nhuman\nrespondents\nremained\nunchanged.\nConversely,\nthe\naddition\nof\nimages\nin\nthe\nchallenging\nNEJM\nclinicopathological\nconferences\nreduced\nperformance\ncompared\nto\nusing\ntext\nalone.\nOverall,\nthese\nresults\nsuggest\nthat\nmultimodal\nAI\nmodels\nmay\nbe\nuseful\nin\nmedical\ndiagnostic\nreasoning\nbut\nthat\ntheir\naccuracy\nmay\ndepend\nheavily\non\ncontext.\nIn\nthe\nNEJM\nclinicopathological\nconferences,\nproviding\nimage\ndata\nparadoxically\ndiminished\nmodel\nperformance.\nThese\ncases\ncontain\nan\nabundance\nof\ninformative\ntext,\nwhich\nalone\nallowed\nGPT-4V\n(Text\nOnly)\nto\ndetermine\nthe\ncorrect\ndiagnosis\nwithin\nthe\ndifferential\nin\n80%\nof\ncases,\noutperforming\na\nrecent\nstudy\n9\nusing\nthe\nsame\nset\nof\nclinicopathological\nconferences\n(64%\nof\ncases).\nWe\nnote\nthat\nthe\nprevious\nanalysis\nprovided\ntabular\ndata\nsuch\nas\nlaboratory\nvalues\nto\nGPT-4\nwhereas\nwe\nincluded\nonly\nthe\ntext\nfrom\nthe\ncase\npresentation\nitself.\nFurthermore,\nin\nour\nstudy,\nthe\naddition\nof\nimages\nin\nmultimodal\nGPT-4V\nworsened\nperformance\n(58%\nof\ncases)\nin\nthe\nclinicopathological\nconferences.\nOne\npossible\nexplanation\nfor\nthese\nfindings\nis\nthat\nthe\nincreased\ndata\n15\nwere\nredundant\nwith\ntext\nsummaries\nin\nthe\ncase\npresentation\nand\ndiluted\nthe\ncontributions\nof\nimportant\ninformation\nin\nthe\ntext.\nOur\nstudy\ndemonstrates\nthat\ntext-based\ncontext\nis\ncritical\nfor\nthe\nperformance\nof\nvision-language\nmodels.\nA\nrecent\nstudy\nlimited\nto\nradiology\nand\npathology\nimages,\nand\nwithout\na\nhuman\nbaseline,\nshowed\nlimited\ndiagnostic\nperformance\nof\nGPT-4V.\n16\nConsistent\nwith\nthis\nstudy,\nour\nfindings\nshowed\ndiminished\nperformance\nof\nGPT-4V\non\nradiology\nimages\nin\nthe\n12 NEJM\nImage\nChallenge\ncases,\nthough\nstill\nmatching\nthat\nof\nhuman\nrespondents.\nAcross\nthe\nmany\nother\nimage\ntypes,\nGPT-4V\ndemonstrated\nincreased\nmultimodal\nperformance\nand\nthe\nability\nto\nreason\nusing\naccompanying\ninformative\ntext.\nAlthough\nour\nstudy\ndoes\nnot\nprovide\ncomparisons\nwith\nexpert\nphysicians,\nthe\nsteady\nimprovement\nof\nmultimodal\nlanguage\nmodels\npresents\nthe\npotential\nto\neventually\nbroaden\naccess\nto\nhigh-quality\ninterpretation\nof\nclinical\nimages\nand\ncases.\nOur\nstudy\nhas\nseveral\nlimitations.\nFirst,\nsince\nGPT-4V\nis\nnot\nopen-source,\nthe\ndata\nused\nin\nmodel\npre-training\nare\nunknown\nand\nmodel\nupdates\nover\ntime\nmay\naffect\nreproducibility\nof\nresults.\nHowever,\nour\nresults\ndo\nnot\nshow\ndiminished\nperformance\nfor\ncases\npublished\nafter\nthe\ntraining\ncut-off\ndate.\nSecond,\nmultiple-choice\nquestions\nare\nnot\nrepresentative\nof\nthe\nbreadth\nof\nclinical\ndecision-making.\nThird,\nthe\nNEJM\nImage\nChallenge\nand\nclinicopathologic\nconferences\noften\nreflect\ninteresting,\nunusual,\nor\neducational\ncases\nrather\nthan\ncases\nthat\nwould\nbe\ncommonly\nobserved\n\u201cin-the-wild.\u201d\nFinally,\nrecorded\nresponses\ndo\nnot\nnecessarily\ncome\nfrom\nunique\nrespondents,\nand\nsome\nof\nthese\nmay\nreflect\nblind\nguessing.\nDeep\nlearning\ntechniques\nhave\ndemonstrated\nincreasing\ncapabilities\nin\nmedicine.\nLarge\nlanguage\nmodels\n(LLMs)\nsuch\nas\nLLaMa,\n17\nGPT-3,\n18\nand\nGPT-4\n6\nhave\npassed\nthe\nUSMLE\nby\nover\n20\npoints,\n7\nperform\nwell\non\nmedical\nquestion\nanswering\nbenchmarks,\n19\nand\nproduce\nsensible\ndifferential\ndiagnoses\non\nNEJM\nclinicopathologic\nconferences\nusing\ntext\nalone.\n9\nMed-PaLM\nM,\na\nrecently\ndeveloped\nmultimodal\nlanguage\nmodel\ncombining\nPaLM\nand\na\nvision\ntransformer,\n20\nshowed\nstate-of-the-art\nperformance\nin\nmultimodal\ntasks.\nOur\nfindings\nabout\nGPT-4V\non\nchallenging\nmedical\ncases\npresent\na\ncompelling\nproof-of-concept\ntowards\nfurther\ndevelopment\nof\nmultimodal\nAI\ntools\nin\nmedicine.\nFurther\nimprovements\nmay\ncome\nfrom\nfine-tuning\nthe\nbaseline\nmodel\n18,21\nor\nmethodological\nadvances\nthat\nimprove\nthe\nmodel\u2019s\nimage-based\nassessments.\nFuture\nresearch\non\nmultimodal\nAI\nshould\naccount\nfor\nhuman\nuse\nof\nsuch\nsystems.\nThe\ndiagnostic\nprocess\nis\nreplete\nwith\ndifferent\nmodes\nof\ninput,\nincluding\nspoken\nand\nwritten\n13 language,\nclinical\nimages,\nthe\nphysical\nexam,\nand\nother\nvisual\nobservations.\nEvidence\nfrom\nradiology\nand\nnon-medical\nfields\nsuggest\nthat\nAI\nrecommendations\ncan\naffect\nhuman\nbehavior\nin\nunexpected\nways,\neven\ndecreasing\nuser\naccuracy\ndespite\ngood\nmodel\nperformance.\n22\nOther\nchallenges\ninclude\nthe\nrisk\nof\nshortcut\nreasoning,\n23\nincluding\nstereotyping\nor\nbias,\n24\nthat\nmay\noccur\nwhen\nAI\nmodels\nare\ntasked\nwith\nformulating\npredictions\nabsent\nsufficient\nevidence.\nAs\ninput\nmodes\ncontinue\nto\nmultiply,\ncomprehensive\nstudies\non\nthe\nmany\nopportunities\nand\nlimitations\nof\nvision-language\nmodels\nin\nAI\nwill\nbe\nnecessary\nprior\nto\nclinical\nuse.\n14 REFERENCES\n1.\nLedley\nRS,\nLusted\nLB.\nReasoning\nfoundations\nof\nmedical\ndiagnosis;\nsymbolic\nlogic, \nprobability,\nand\nvalue\ntheory\naid\nour\nunderstanding\nof\nhow\nphysicians\nreason.\nScience \n1959;130(3366):9\u201321.\n2.\nSteinkamp\nJ,\nKantrowitz\nJJ,\nAiran-Javia\nS.\nPrevalence\nand\nSources\nof\nDuplicate \nInformation\nin\nthe\nElectronic\nMedical\nRecord.\nJAMA\nNetw\nOpen\n2022;5(9):e2233348.\n3.\nGulshan\nV,\nPeng\nL,\nCoram\nM,\net\nal.\nDevelopment\nand\nValidation\nof\na\nDeep\nLearning \nAlgorithm\nfor\nDetection\nof\nDiabetic\nRetinopathy\nin\nRetinal\nFundus\nPhotographs.\nJAMA \n2016;316(22):2402\u201310.\n4.\nAbr\u00e0moff\nMD,\nLavin\nPT,\nBirch\nM,\nShah\nN,\nFolk\nJC.\nPivotal\ntrial\nof\nan\nautonomous\nAI-based \ndiagnostic\nsystem\nfor\ndetection\nof\ndiabetic\nretinopathy\nin\nprimary\ncare\noffices.\nNPJ\nDigit \nMed\n2018;1:39.\n5.\nLee\nP,\nBubeck\nS,\nPetro\nJ.\nBenefits,\nlimits,\nand\nrisks\nof\nGPT-4\nas\nan\nAI\nchatbot\nfor\nmedicine. \nN\nEngl\nJ\nMed\n2023;388(13):1233\u20139.\n6.\nOpenAI.\nGPT-4\nSystem\nCard.\n2023;Available\nfrom: \nhttps://cdn.openai.com/papers/gpt-4-system-card.pdf\n7.\nNori\nH,\nKing\nN,\nMcKinney\nSM,\nCarignan\nD,\nHorvitz\nE.\nCapabilities\nof\nGPT-4\non\nMedical \nChallenge\nProblems\n[Internet].\narXiv\n[cs.CL].\n2023;Available\nfrom: \nhttp://arxiv.org/abs/2303.13375\n8.\nAyers\nJW,\nPoliak\nA,\nDredze\nM,\net\nal.\nComparing\nPhysician\nand\nArtificial\nIntelligence \nChatbot\nResponses\nto\nPatient\nQuestions\nPosted\nto\na\nPublic\nSocial\nMedia\nForum.\nJAMA \nIntern\nMed\n2023;183(6):589\u201396.\n9.\nKanjee\nZ,\nCrowe\nB,\nRodman\nA.\nAccuracy\nof\na\nGenerative\nArtificial\nIntelligence\nModel\nin\na \nComplex\nDiagnostic\nChallenge.\nJAMA\n2023;330(1):78\u201380.\n10.\nOpen\nAI.\nGPT-4V(ision)\nSystem\nCard\n[Internet].\n[cited\n2023\nOct\n25];Available\nfrom: \nhttps://cdn.openai.com/papers/GPTV_System_Card.pdf\n11.\nImage\nChallenge\n[Internet].\nNew\nEngland\nJournal\nof\nMedicine.\n[cited\n2023\nOct\n25];Available \nfrom:\nhttps://www.nejm.org/image-challenge\n12.\nDiao\nJA,\nAdamson\nAS.\nRepresentation\nand\nmisdiagnosis\nof\ndark\nskin\nin\na\nlarge-scale\nvisual \ndiagnostic\nchallenge.\nJ\nAm\nAcad\nDermatol\n2022;86(4):950\u20131.\n13.\nKojima\nT,\nGu\nSS,\nReid\nM,\nMatsuo\nY,\nIwasawa\nY.\nLarge\nLanguage\nModels\nare\nZero-Shot \nReasoners\n[Internet].\narXiv\n[cs.CL].\n2022;22199\u2013213.\nAvailable\nfrom: \nhttps://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16 \nf326-Paper-Conference.pdf\n14.\nBond\nWF,\nSchwartz\nLM,\nWeaver\nKR,\nLevick\nD,\nGiuliano\nM,\nGraber\nML.\nDifferential \ndiagnosis\ngenerators:\nan\nevaluation\nof\ncurrently\navailable\ncomputer\nprograms.\nJ\nGen\nIntern \nMed\n2012;27(2):213\u20139.\n15 15.\nLiu\nNF,\nLin\nK,\nHewitt\nJ,\net\nal.\nLost\nin\nthe\nMiddle:\nHow\nLanguage\nModels\nUse\nLong\nContexts \n[Internet].\narXiv\n[cs.CL].\n2023;Available\nfrom:\nhttp://arxiv.org/abs/2307.03172\n16.\nYan\nZ,\nZhang\nK,\nZhou\nR,\nHe\nL,\nLi\nX,\nSun\nL.\nMultimodal\nChatGPT\nfor\nMedical\nApplications: \nan\nExperimental\nStudy\nof\nGPT-4V\n[Internet].\narXiv\n[cs.CV].\n2023;Available\nfrom: \nhttp://arxiv.org/abs/2310.19061\n17.\nTouvron\nH,\nMartin\nL,\nStone\nK,\net\nal.\nLlama\n2:\nOpen\nFoundation\nand\nFine-Tuned\nChat \nModels\n[Internet].\narXiv\n[cs.CL].\n2023;Available\nfrom:\nhttp://arxiv.org/abs/2307.09288\n18.\nBrown\nT,\nMann\nB,\nRyder\nN,\net\nal.\nLanguage\nmodels\nare\nfew-shot\nlearners.\nAdv\nNeural\nInf \nProcess\nSyst\n2020;33:1877\u2013901.\n19.\nSinghal\nK,\nAzizi\nS,\nTu\nT,\net\nal.\nLarge\nlanguage\nmodels\nencode\nclinical\nknowledge.\nNature \n[Internet]\n2023;Available\nfrom:\nhttp://dx.doi.org/10.1038/s41586-023-06291-2\n20.\nTu\nT,\nAzizi\nS,\nDriess\nD,\net\nal.\nTowards\nGeneralist\nBiomedical\nAI\n[Internet].\narXiv\n[cs.CL]. \n2023;Available\nfrom:\nhttp://arxiv.org/abs/2307.14334\n21.\nWei\nJ,\nWang\nX,\nSchuurmans\nD,\net\nal.\nChain-of-thought\nprompting\nelicits\nreasoning\nin\nlarge \nlanguage\nmodels\n[Internet].\narXiv\n[cs.CL].\n2022;24824\u201337.\nAvailable\nfrom: \nhttps://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31ab \nca4-Paper-Conference.pdf\n22.\nDell\u2019Acqua\nF,\nMcFowland\nE,\nMollick\nER,\net\nal.\nNavigating\nthe\nJagged\nTechnological \nFrontier:\nField\nExperimental\nEvidence\nof\nthe\nEffects\nof\nAI\non\nKnowledge\nWorker \nProductivity\nand\nQuality\n[Internet].\n2023\n[cited\n2023\nNov\n6];Available\nfrom: \nhttps://papers.ssrn.com/abstract=4573321\n23.\nGeirhos\nR,\nJacobsen\nJ-H,\nMichaelis\nC,\net\nal.\nShortcut\nlearning\nin\ndeep\nneural\nnetworks. \nNature\nMachine\nIntelligence\n2020;2(11):665\u201373.\n24.\nOmiye\nJA,\nLester\nJC,\nSpichak\nS,\nRotemberg\nV,\nDaneshjou\nR.\nLarge\nlanguage\nmodels \npropagate\nrace-based\nmedicine.\nNPJ\nDigit\nMed\n2023;6(1):195.\n16 Accuracy\nof\na\nvision-language\nmodel\non \nchallenging\nmedical\ncases\nTable\n1.\nAccuracy\nof\na\nVision-Language\nModel\nvs.\nHuman\nRespondents\non\nChallenging\nMedical \nCases\n....................................................................................................................................................\n18\nFigure\n1\n.\nEvidence\nof\nMultimodal\nClinical\nReasoning\nby\nGPT-4V.\n.......................................................\n19\nFigure\n2.\nAccuracy\nby\nImage\nType\nand\nImage\nSkin\nColor.\n...................................................................\n20\nFigure\n3.\nMultimodal\nReasoning\nExplanations\nProvided\nby\nGPT-4V\n....................................................\n21\nFigure\n4.\nMultimodal\nEvaluation\non\nClinicopathological\nConferences\n..................................................\n25\n17 Table\n1.\nAccuracy\nof\na\nVision-Language\nModel\nversus\nHuman\nRespondents\non \nChallenging\nMedical\nCases\nCase \nCategory\nNo. \nCases\nMedian \nNo.\nHuman \nResponses\nHuman \nAccuracy \n(95%\nCI)\nGPT-4V \nAccuracy \n(95%\nCI)\nAbsolute \nDifference \n(95%\nCI)\nRelative \nDifference \n(95%\nCI)\nP-value\nOverall\n934\n89,918\n0.49\n(0.49\nto\n0.50)\n0.61 \n(0.58\nto\n0.64)\n0.12\n(0.08\nto\n0.15)\n23%\n(17%\nto\n30%)\n<\n0.001\nDifficulty\nEasy\n303\n79,101\n0.65\n(0.64\nto\n0.66)\n0.72 \n(0.66\nto\n0.77)\n0.072\n(0.021\nto\n0.12)\n11%\n(3.3%\nto\n19%)\n<\n0.01\nMedium\n318\n89,162\n0.49\n(0.49\nto\n0.50)\n0.67 \n(0.62\nto\n0.72)\n0.18\n(0.12\nto\n0.23)\n36%\n(26%\nto\n46%)\n<\n0.001\nHard\n313\n105,457\n0.35\n(0.34\nto\n0.36)\n0.44 \n(0.39\nto\n0.50)\n0.10\n(0.040\nto\n0.15)\n28%\n(13%\nto\n43%)\n<\n0.01\nDisagreement\nLow\n312\n82,949\n0.64\n(0.63\nto\n0.65)\n0.69 \n(0.63\nto\n0.74)\n0.051\n(-0.0011\nto\n0.10)\n8.0%\n(-0.18%\nto\n16%)\n0.055\nMedium\n311\n89,630\n0.49\n(0.48\nto\n0.49)\n0.70 \n(0.64\nto\n0.75)\n0.21\n(0.16\nto\n0.26)\n43%\n(32%\nto\n53%)\n<\n0.001\nHigh\n311\n103,804\n0.36\n(0.35\nto\n0.37)\n0.45 \n(0.39\nto\n0.50)\n0.087\n(0.031\nto\n0.14)\n25%\n(10%\nto\n39%)\n<\n0.01\nTime\nPeriod\n2005-2022\n893\n92,303\n0.49\n(0.49\nto\n0.50)\n0.60 \n(0.57\nto\n0.64)\n0.11\n(0.076\nto\n0.14)\n22%\n(16%\nto\n29%)\n<\n0.001\n2023\n41\n36,673\n0.51\n(0.47\nto\n0.54)\n0.76 \n(0.60\nto\n0.88)\n0.25\n(0.11\nto\n0.39)\n49%\n(22%\nto\n75%)\n<\n0.01\nTable\n1.\nAccuracy\nof\na\nVision-Language\nModel\nvs.\nHuman\nRespondents\non\nChallenging\nMedical \nCases.\nPerformance\ncomparisons\nbetween\nGPT-4V\nand\nhuman\nrespondents\non\nNEJM\nImage \nChallenge\ncases\nbetween\n2005\nand\n2023.\nAccuracy\nis\nshown\noverall\nand\nby\ncase\ndifficulty,\nlevel\nof \nhuman\ndisagreement,\nand\ntime\nperiod.\nThe\naccuracy\nfor\nhuman\nrespondents\nis\nthe\nmean\nof\nthe \nproportion\ncorrect\nfor\neach\nset\nof\ncases.\nThe\naccuracy\nfor\nGPT-4V\nis\nthe\nproportion\nof\ncorrect \nresponses\nfor\neach\nset\nof\ncases.\n95%\nconfidence\nintervals\nfor\nhuman\naccuracy\nare\ncomputed\nfrom\na \nt-distribution.\n95%\nconfidence\nintervals\n(95%\nCIs)\nfor\nGPT-4V\naccuracy\nare\ncomputed\nusing \nClopper-Pearson\nintervals.\nP-values\nand\n95%\nCIs\nfor\nabsolute\ndifference\nwere\ncomputed\nusing\na\nt-test \nbetween\nGPT-4V\nmean\naccuracy\nand\nhuman\nmean\naccuracy.\nP-values\nwere\nadjusted\nfor\nmultiple \ntests\nusing\nthe\nHolm\u2013Bonferroni\nprocedure.\nThe\nrelative\ndifference\nestimates\nand\n95%\nCIs\nwere \ncomputed\nby\nbootstrapping\nwith\n5000\nreplicates.\n18 Figure\n1.\nEvidence\nof\nMultimodal\nClinical\nReasoning\nby\nGPT-4V\nA.\nComparison\nof\nGPT-4V\nand\nHuman\nRespondents\nAcross\nModalities\nB.\nOverall\nAccuracy\nof\nGPT-4V\nby\nModality\nCompared\nto\nHuman\nRespondents\nFigure\n1.\nEvidence\nof\nMultimodal\nClinical\nReasoning\nby\nGPT-4V.\nA.\nAccuracy\nof\nGPT-4V\nwhen\nusing\nimages\nonly,\ntext\nonly,\nor\nboth\non\n934\nNEJM\nImage\nChallenge\ncases\ncompared\nto\nhuman\nrespondents,\nstratified\nby\ndecile\nof\nquestion\nword\ncount.\nWord\ncount\nranges\nfrom\n4\nto\n128.\nB.\nOverall\naccuracy\nof\nGPT-4V\nacross\nall\n934\ncases\nwhen\nusing\nimages\nonly,\ntext\nonly,\nor\nboth\ncompared\nto\nhuman\nrespondents.\nError\nbars\nindicate\n95%\nCIs\nand\nthe\ndashed\nblack\nline\nindicates\nrandom\nguesses.\nA\nrefusal\nto\nanswer\nhere\nis\ninterpreted\nas\nincorrect,\nwhich\nexplains\nan\naccuracy\nless\nthan\nrandom.\nFor\nexample,\nfor\ntrials\nwith\ntext\nonly,\nthe\nmodel\nwould\nrefuse\nto\nrespond\nwhen\nthe\nquestion\nwas\n\u201cWhat\nis\nthe\ndiagnosis\u201d\nwith\nno\nimage\nfor\ncontext.\n19\n Figure\n2.\nAccuracy\nby\nImage\nType\nand\nImage\nSkin\nColor\nA.\nPerformance\nof\nGPT-4V\nversus\nHuman\nRespondents\nby\nImage\nType\nB.\nPerformance\nof\nGPT-4V\nvs.\nHuman\nRespondents\nby\nFitzpatrick\nSkin\nType\nFigure\n2.\nAccuracy\nby\nImage\nType\nand\nImage\nSkin\nColor. \nAccuracy\nof\nGPT-4V\nvs.\nhuman\nrespondents\nin\nthe\nNEJM\nImage\nChallenges\nby\nA.\ntype\nof\nimage\nand \nB.\nFitzpatrick\nskin\ntype.\nImage\nannotations\nwere\nretrieved\nfrom\nDiao\net\nal.\nJAAD\n2020\nand\nFitzpatrick \nskin\ntype\nwas\nrated\nby\na\nboard-certified\ndermatologist,\ncategorized\ninto\n\u201clight\u201d\n(1-2),\n\u201cintermediate\u201d \n(3-4),\nand\n\u201cdark\u201d\n(5-6).\nError\nbars\nare\n95%\nconfidence\nintervals\nand\nthe\ndashed\nblack\nline\nindicates \nrandom\nguesses.\n20\n Figure\n3.\nMultimodal\nReasoning\nExplanations\nProvided\nby\nGPT-4V\nA.\nGPT-4V\ncorrect\non\ndifficult\nquestion\nNEJM\nImage\nChallenge\n06-14-2007\nQuestion\nThese\nlesions\nappeared\nin\na\nrecent\nimmigrant\nfrom\nPakistan.\nThe \nlesions\nwere\nneither\npruritic\nnor\nhypoesthetic.\nWhat\nis\nthe\ndiagnosis?\nRespondents\n1.\nGranuloma\nannulare\n(23%) \n2.\nScrofula\n(7%) \n3.\nLeprosy\n(25%) \n4.\nPityriasis\nrosea\n(15%) \n5.\nTinea\ncorporis\n(29%)\n[max\nrespondents]\nGPT-4V\n(Image\nOnly):\nBased\non\nthe\nimage\nprovided,\nthe\nmost\nlikely\ndiagnosis\nis\n'Scrofula'.\nGPT-4V\n(Text\nOnly):\nGiven\nthat\nthe\nindividual\nis\na\nrecent\nimmigrant\nfrom\nPakistan\nand\npresents\nwith\nskin\nlesions\nthat\nare\nneither\npruritic\n(itchy)\nnor\nhypoesthetic\n(reduced\nsense\nof\ntouch),\nthe\nmost\nlikely\ndiagnosis\nfrom\nthe\nprovided\noptions\nis\n\"Leprosy\"\n(also\nknown\nas\nHansen's\ndisease).\nLeprosy\nis\ncaused\nby\nMycobacterium\nleprae\nand\nis\nmore\nprevalent\nin\ncertain\nparts\nof\nthe\nworld,\nincluding\nparts\nof\nPakistan.\nThe\nloss\nor\ndecrease\nof\nsensation\n(hypoesthesia)\nis\na\nhallmark\nof\nleprosy,\nbut\nnot\nall\nlesions\nwill\nnecessarily\nmanifest\nthis\nsymptom\nimmediately.\nSo,\nthe\nmost\nprobable\ndiagnosis\nis\n\"Leprosy\".\nMultimodal\nGPT-4V:\nBased\non\nthe\nimage\nprovided\nand\nthe\ninformation\ngiven,\nthe\nmost\nlikely\ndiagnosis\nfor\nthese\nlesions\nin\na\nrecent\nimmigrant\nfrom\nPakistan\nthat\nare\nneither\npruritic\nnor\nhypoesthetic\nis\n'Leprosy'.\nMultimodal\nGPT-4V\nwith\nCoT:\nAlright,\nlet's\napproach\nthis\nmethodically.\nCase\nInformation:\nLesions\non\nthe\nskin.\nNeither\npruritic\n(itchy)\nnor\nhypoesthetic\n(reduced\nsense\nof\ntouch).\nRecent\nimmigrant\nfrom\nPakistan.\nDifferential\nDiagnoses:\n\u25cf\nGranuloma\nannulare:\nThis\ncondition\nusually\npresents\nas\nraised,\nreddish\nor\nskin-colored\nbumps\nthat\nform\nring\npatterns.\nThey\noften\nappear\non\nthe\nhands\nand\nfeet.\nThere's\nno\nitchiness\nassociated,\nwhich\nmatches\nthe\ndescription,\nbut\nthe\noverall\npresentation\ndoesn't\nentirely\nmatch.\n\u25cf\nScrofula\n(Tuberculous\nlymphadenitis):\nThis\nis\na\nform\nof\ntuberculosis\naffecting\nthe\nlymph\nnodes,\ntypically\nthe\ncervical\nnodes.\nThe\npatient's\nbackground\nas\na\nrecent\nimmigrant\nmight\nmake\nthis\na\nconsideration,\nbut\nthe\nimage\ndoes\nnot\ndepict\nenlarged\nlymph\nnodes.\n\u25cf\nLeprosy:\nAlso\nknown\nas\nHansen's\ndisease,\nit's\ncaused\nby\nthe\nbacteria\nMycobacterium\nleprae.\nIt\nleads\nto\nskin\nlesions\nwhich\ncan\nbe\ndiscolored\nand\nmay\nbecome\nnumb\ndue\nto\nnerve\ninvolvement.\nGiven\nthe\ndescription\nthat\nthe\nlesions\nare\nnot\nhypoesthetic,\nit\nmight\nnot\nbe\nthe\nfirst\nchoice,\nbut\nleprosy\nis\nendemic\nin\nsome\nparts\nof\nPakistan.\n\u25cf\nPityriasis\nrosea:\nIt\nstarts\nas\na\nlarge\nrounded\nor\noval\npatch\non\nthe\nchest,\nabdomen,\nor\nback.\nAfter\n1-2\nweeks,\nsmaller\npatches\nmay\nappear\non\nthe\nback\nor\nchest.\nIt's\ntypically\nitchy,\nwhich\ndoesn't\nalign\nwith\nour\ndescription.\n\u25cf\nTinea\ncorporis:\nCommonly\nknown\nas\nringworm,\nit's\na\nfungal\ninfection\nof\nthe\nskin.\nThe\nrash\nis\ntypically\nring-shaped,\nbut\nit\nis\nitchy,\nwhich\nagain\ndoesn't\nalign\nwith\nour\ndescription.\nConclusion:\nBased\non\nthe\nprovided\nimage,\nthe\ndescription,\nand\nthe\npatient's\nbackground,\nthe\nmost\nlikely\ndiagnosis\nwould\nbe\nLeprosy.\n21\n B.\nGPT-4V\n(Text\nOnly)\ncorrect\non\ndifficult\nquestion\nNEJM\nImage\nChallenge\n03-24-201 1\nQuestion\nUltraviolet\nlight\nwas\nshone\non\nthis\npatient's\nrash.\nWhat\nis\nthe \ndiagnosis?\nRespondents\n1.\nErythrasma\n(28%) \n2.\nIntertrigo\n(9%) \n3.\nPityriasis\nrosea\n(14%) \n4.\nPsoriasis\n(9%) \n5.\nTinea\nversicolor\n(39%)\n[max\nrespondents]\nGPT-4V\n(Image\nOnly):\nBased\non\nthe\nimage\nprovided,\nmy\nanswer\nwould\nbe:\n'Erythrasma'\nGPT-4V\n(Text\nOnly):\nThe\nuse\nof\nultraviolet\nlight,\nspecifically\nWood's\nlamp\nexamination,\ncan\nhelp\ndiagnose\ncertain\nskin\nconditions\nbased\non\nthe\nfluorescence\nor\ncoloration\nthey\nproduce\nunder\nthis\nlight.\nAmong\nthe\nchoices\ngiven:\n'Erythrasma'\nis\ncaused\nby\nthe\nbacteria\nCorynebacterium\nminutissimum\nand\nwill\nfluoresce\na\ncoral-red\ncolor\nunder\na\nWood's\nlamp.\n'Intertrigo'\nis\nskin\nirritation\nin\nthe\nfolds\nof\nthe\nskin,\noften\ndue\nto\nmoisture,\nfriction,\nand\nbacterial\nor\nfungal\ncolonization.\nIt\ndoes\nnot\nspecifically\nfluoresce\nunder\na\nWood's\nlamp.\n'Pityriasis\nrosea'\nis\na\nself-limited\nrash\nthat\nusually\nbegins\nwith\na\n\"herald\npatch\"\nfollowed\nby\nthe\nappearance\nof\nsmaller\nlesions.\nIt\ndoes\nnot\nfluoresce\nunder\na\nWood's\nlamp.\n'Psoriasis'\nis\nan\nautoimmune\ncondition\nthat\ncauses\nthick,\nscaly\nplaques\non\nthe\nskin.\nIt\nalso\ndoes\nnot\nfluoresce\nunder\nWood's\nlamp.\n'Tinea\nversicolor'\nis\na\nfungal\ninfection\ncaused\nby\nMalassezia\nspecies\nand\nmight\nshow\na\nyellowish\nor\ngold\nfluorescence\nunder\na\nWood's\nlamp,\nthough\nit's\nnot\nalways\ndefinitive.\nGiven\nthis\ninformation\nand\nthe\nlimited\ncontext\nof\nthe\nquestion,\nthe\ndiagnosis\nthat\ncan\nbe\nspecifically\nidentified\nby\nultraviolet\nlight\n(Wood's\nlamp)\nis\n'Erythrasma'.\nSo,\nthe\nanswer\nis:\nErythrasma.\nMultimodal\nGPT-4V:\nThe\nimage\nshows\na\nrash\nthat\nfluoresces\ncoral\nred\nunder\nultraviolet\nlight,\nwhich\nis\ncharacteristic\nof\nErythrasma\ncaused\nby\nthe\nbacteria\nCorynebacterium\nminutissimum.\nThe\ncorrect\nanswer\nis:\n'Erythrasma'.\nMultimodal\nGPT-4V\nwith\nCoT:\nAlright!\nLet's\nbreak\nit\ndown\nstep\nby\nstep:\nUltraviolet\nLight\nExamination:\nWhen\nultraviolet\nlight\nis\nshone\non\ncertain\nskin\nconditions,\nthey\nmay\nfluoresce\nor\nglow.\nThis\ntechnique\ncan\nhelp\ndifferentiate\ncertain\nskin\nconditions\nfrom\nothers.\nDescription\nof\nthe\nImage:\nThe\nimage\nappears\nto\nshow\na\nrash\nwith\nan\nirregular\npattern\nand\nsome\nareas\nthat\nseem\nto\nbe\nfluorescing\nunder\nthe\nultraviolet\nlight.\nOptions\nGiven:\n\u25cf\nErythrasma:\nThis\nis\na\nbacterial\ninfection\nthat\ncan\nfluoresce\na\ncoral-red\ncolor\nunder\nultraviolet\nlight.\nIt's\ncaused\nby\nthe\nCorynebacterium\nminutissimum\nbacteria\nand\noften\naffects\nareas\nwhere\nthe\nskin\nfolds,\nlike\nthe\ngroin\nor\narmpits.\n\u25cf\nIntertrigo:\nThis\nis\na\nrash\nthat\noccurs\nin\nskin\nfolds,\ncaused\nby\nfriction.\nIt\ndoesn't\ntypically\nfluoresce\nunder\nultraviolet\nlight.\n\u25cf\nPityriasis\nrosea:\nThis\nis\na\nskin\nrash\nthat\nusually\nappears\non\nthe\ntorso,\narms,\nand\nlegs.\nIt's\ncharacterized\nby\na\nlarge,\nround\nspot\ncalled\na\n\"herald\npatch,\"\nfollowed\nby\nsmaller\npatches.\nIt\ndoesn't\nfluoresce\nunder\nUV\nlight.\n\u25cf\nPsoriasis:\nThis\nis\na\nchronic\nskin\ncondition\nthat\ncauses\ncells\nto\nbuild\nup\nrapidly\non\nthe\nsurface\nof\nthe\nskin.\nThe\nextra\nskin\ncells\nform\nscales\nand\nred\npatches\nthat\nare\nsometimes\npainful\nor\nitchy.\nPsoriasis\ndoes\nnot\nfluoresce\nunder\nUV\nlight.\n\u25cf\nTinea\nversicolor:\nThis\nis\na\nfungal\ninfection\nof\nthe\nskin.\nIt's\nalso\nknown\nas\npityriasis\nversicolor.\nThe\nyeast\ninterferes\nwith\nthe\nnormal\npigmentation\nof\nthe\nskin,\nresulting\nin\nsmall,\ndiscolored\npatches.\nUnder\nultraviolet\nlight,\ntinea\nversicolor\ncan\nfluoresce\na\nyellowish-green\ncolor.\nConclusion:\nBased\non\nthe\nimage\nand\nthe\nfluorescence\nseen\nunder\nultraviolet\nlight,\nthe\nmost\nlikely\ndiagnosis\nis\nErythrasma\ndue\nto\nthe\ncoral-red\nfluorescence\nwhich\nis\ncharacteristic\nof\nthis\ncondition.\n22\n C.\nGPT-4V\nincorrect\non\neasy\nquestion\nNEJM\nImage\nChallenge\n07-03-2008\nQuestion\nWhat\nis\nthe\ndiagnosis?\nRespondents\n1.\nFlail\nchest\n(4%) \n2.\nPectus\narcuatum\n(5%) \n3.\nPectus\ncarinatum\n(9%) \n4.\nPectus\nexcavatum\n(79%)\n[max\nrespondents] \n5.\nSpondylocostal\ndysostosis\n(3%)\nGPT-4V\n(Image\nOnly):\nBased\non\nthe\nimage\nprovided,\nthe\nmost\nlikely\ndiagnosis\nis\n'Pectus\ncarinatum'.\nGPT-4V\n(Text\nOnly):\nUnfortunately,\nyou\nhaven't\nprovided\nthe\ncase\ndescription,\nso\nI\ncan't\ndetermine\nthe\nmost\nlikely\ndiagnosis\nfrom\nthe\noptions\ngiven.\nPlease\nprovide\nthe\ncase\ndescription\nso\nI\ncan\nassist\nyou\nfurther.\nMultimodal\nGPT-4V:\nBased\non\nthe\nprovided\nimage\nand\nthe\nlist\nof\noptions,\nthe\nmost\nlikely\ndiagnosis\nis\n\"pectus\ncarinatum.\"\nMultimodal\nGPT-4V\nwith\nCoT:\nAlright,\nlet's\napproach\nthis\nsystematically.\nImage\nDescription:\nThe\nimage\nappears\nto\nshow\nthe\nchest\nregion\nof\nan\nindividual.\nThere\nseems\nto\nbe\na\nprominence\nor\nprotrusion\nin\nthe\nchest\nwall,\nspecifically\nat\nthe\nsternum\narea.\nPossible\nDiagnoses:\n\u25cf\nFlail\nchest:\nThis\nis\na\nlife-threatening\nmedical\ncondition\nwhere\na\nsegment\nof\nthe\nrib\ncage\nbreaks\nand\ndetaches\nfrom\nthe\nrest\nof\nthe\nchest\nwall.\nThe\nimage\ndoes\nnot\ndepict\nmultiple\nbroken\nribs\ncausing\na\nsegment\nof\nchest\nwall\nto\nmove\nparadoxically.\n\u25cf\nPectus\narcuatum:\nThis\nis\na\nless\ncommonly\nreferenced\ncondition\nand\nis\nnot\na\nstandard\nterm\nin\nmany\nmedical\ntextbooks.\nIt\nmay\nbe\na\nvariation\nor\nsubtype\nof\nanother\ncondition,\nbut\nthe\nimage\ndoes\nnot\nshow\nany\ncharacteristics\nspecifically\npointing\nto\nthis.\n\u25cf\nPectus\ncarinatum:\nAlso\nknown\nas\n\"pigeon\nchest\",\nit\nis\ncharacterized\nby\na\nprotrusion\nof\nthe\nsternum\nand\nribs.\nThe\nsternum\nappears\nto\nbe\npushed\noutward.\nThis\nseems\nto\nfit\nwith\nthe\nimage\nprovided.\nPectus\nexcavatum:\nAlso\nknown\nas\n\"funnel\nchest\",\nit\nis\nthe\nopposite\nof\nPectus\ncarinatum.\nIn\nthis\ncondition,\nthere\nis\na\nconcave\nappearance\nor\nindentation\nin\nthe\nchest\nwall.\nThis\ndoes\nnot\nfit\nthe\nimage's\nappearance.\n\u25cf\nSpondylocostal\ndysostosis:\nThis\nis\na\nrare\ncongenital\ndisorder\ninvolving\nvertebral\nand\nrib\nanomalies.\nIt\nwould\nlikely\npresent\nwith\nmore\nwidespread\nskeletal\nanomalies\nand\nnot\njust\na\nsingular\nprotrusion\nlike\nseen\nin\nthe\nimage.\nConclusion:\nBased\non\nthe\nimage\nand\nthe\navailable\noptions,\nthe\nmost\nlikely\ndiagnosis\nis\nPectus\ncarinatum.\n23\n D.\nGPT-4V\n(Text\nOnly)\nindeterminate\non\neasy\nquestion\nNEJM\nImage\nChallenge\n01-12-2006\nQuestion\nWhat\nis\nmost\nlikely\nto\naccount\nfor\nthe\nfindings\non\nthis\nabdominal \nradiograph?\nRespondents\n1.\nSchistosomiasis\n(4%) \n2.\nChronic\nlaxative\nuse\n(14%) \n3.\nHyperparathyroidism\n(9%) \n4.\nIschemic\ncolitis\n(5%) \n5.\nIngestion\nof\na\nheavy\nmetal\n(69%)\n[max\nrespondents]\nGPT-4V\n(Image\nOnly):\nBased\non\nthe\nimage\nprovided,\nthe\nradiological\nappearance\nis\nsuggestive\nof\nnumerous\ncalcifications\nwithin\nthe\ncolon, \noften\nreferred\nto\nas\n\"appendicoliths\"\nor\n\"fecaliths\"\nwhen\nin\nthe\nappendix\nor\nfecal\nmatter,\nrespectively.\nThe\nmost\nconsistent\ndiagnosis\nwith\nsuch\na \npresentation\namong\nthe\noptions\nprovided\nwould\nbe:\nChronic\nlaxative\nuse.\nChronic\nlaxative\nuse\ncan\nlead\nto\ncalcium\nor\nbarium\nsalt\ndeposition\nin \nthe\ncolon,\nresulting\nin\nthe\ncharacteristic\nappearance\nof\n\"milk\nof\ncalcium\"\nor\n\"soap\nbubble\"\nappearance\non\nX-rays.\nGPT-4V\n(Text\nOnly):\nTo\nanswer\nthis\nquestion\naccurately,\nI\nwould\nneed\nto\nsee\nthe\nabdominal\nradiograph\nin\nquestion.\nHowever,\ngiven\nthat\nI \ncannot\nsee\nthe\nimage,\nI\ncan\nprovide\nsome\ninsight\ninto\neach\nof\nthe\noptions:\\nSchistosomiasis:\nA\nparasitic\ninfection\nthat\nprimarily\naffects\nthe \nurinary\nand\nintestinal\nsystems.\nRadiographic\nfindings\nmight\nshow\ncalcifications\nin\nthe\nbladder\nwall\nor\nintestines.\nChronic\nlaxative\nuse:\nThis\ncould \nresult\nin\na\nradiograph\nthat\ndisplays\nan\noverall\nloss\nof\nhaustral\nmarkings\nin\nthe\ncolon\n(called\n\"cathartic\ncolon\"),\nwhich\nis\na\nresult\nof\nthe\nlong-term \nstimulant\nlaxative\nuse\ndamaging\nthe\nnerves\nand\nmuscles\nof\nthe\ncolon.\nHyperparathyroidism:\nThis\ncondition\ncan\nresult\nin\nkidney\nstones\nand\nbone \nabnormalities\nlike\nsubperiosteal\nbone\nresorption.\nOn\nan\nabdominal\nradiograph,\nyou\nmight\nsee\nnephrocalcinosis\nor\nrenal\nstones.\nIschemic\ncolitis: \nThis\nis\nwhen\nblood\nflow\nto\na\npart\nof\nthe\ncolon\nis\nreduced.\nAn\nabdominal\nradiograph\nmight\nshow\nbowel\nwall\nthickening\nor\nthumbprinting\ndue\nto \nedema\nand\nhemorrhage.\nIngestion\nof\na\nheavy\nmetal:\nIngestion\nof\ncertain\nheavy\nmetals,\nlike\nlead\nor\nbarium,\nmight\nshow\nup\nas\nopaque\nor\ndense \nareas\non\nthe\nradiograph,\ndepending\non\nthe\nmetal\nand\nits\nconcentration.\nTo\ndetermine\nthe\nmost\nlikely\ncause\nbased\non\nthe\nabdominal\nradiograph, \nI'd\nneed\na\ndescription\nof\nthe\nfindings\nor\nthe\nability\nto\nsee\nthe\nimage\nitself.\nMultimodal\nGPT-4V:\nThe\nimage\nprovided\nis\nan\nabdominal\nradiograph\nthat\ndisplays\ndense\nstippling\nthroughout\nthe\ncolon.\nThis\nfinding\nis \nconsistent\nwith\ningestion\nof\na\nradio-opaque\nsubstance.\nGiven\nthe\noptions:\n'schistosomiasis'\nis\na\nparasitic\ninfection\nthat\naffects\nthe\nliver,\nbladder, \nand\nintestines\nbut\ndoes\nnot\npresent\nas\nradio-opaque\nstippling\nin\nthe\ncolon.\n'chronic\nlaxative\nuse'\ncan\ncause\nmelanosis\ncoli,\nwhich\npresents\nas\na \ndarkening\nof\nthe\ncolon\nwall,\nbut\nit\ndoesn\u2019t\npresent\nas\ndense\nstippling.\n'hyperparathyroidism'\ncan\nlead\nto\nhypercalcemia\nand\nthe\ndevelopment\nof \nkidney\nstones,\nbut\nit\ndoes\nnot\ncause\ndense\nstippling\nin\nthe\ncolon.\n'ischemic\ncolitis'\nresults\nfrom\nreduced\nblood\nflow\nto\nthe\ncolon,\nand\nit\ndoesn't \npresent\nwith\nthis\npattern.\nThe\nmost\nconsistent\nanswer\nwith\nthe\nfindings\nin\nthe\nradiograph\nis:\n'ingestion\nof\na\nheavy\nmetal'\nsuch\nas\nbarium\nor\nlead, \nwhich\ncan\nproduce\nthe\nradio-opaque\nstippling\nseen\nthroughout\nthe\ncolon.\nSo,\nthe\nmost\nlikely\nanswer\nbased\non\nthe\nfindings\non\nthis\nabdominal \nradiograph\nis\n'ingestion\nof\na\nheavy\nmetal'.\nMultimodal\nGPT-4V\nwith\nCoT:\nCertainly,\nlet's\nanalyze\nthe\nimage\nand\nthe\nprovided\noptions\nstep\nby\nstep.\nImage\nAnalysis:\nThe\nradiograph \ndepicts\nmultiple\nsmall\nopacities\nthroughout\nthe\ncolon.\nThese\nopacities\nare\nuniformly\ndistributed\nand\nare\nconsistent\nin\nsize\nand\nappearance.\nThe \npattern\nis\nreminiscent\nof\na\nradiopaque\nsubstance\npresent\nwithin\nthe\ncolon. \nOptions\nAnalysis: \n\u25cf\nSchistosomiasis:\nThis\nis\na\nparasitic\ndisease\ncaused\nby\nblood\nflukes.\nWhile\nit\ncan\naffect\nthe\ngastrointestinal\nsystem,\nit\ndoes\nnot \nproduce\nthe\ntype\nof\nradiographic\nappearance\nshown\nin\nthe\nimage. \n\u25cf\nChronic\nlaxative\nuse:\nChronic\nuse\nof\ncertain\nlaxatives\ncan\nresult\nin\nthe\naccumulation\nof\nresidual\nbarium,\na\nradiopaque\nsubstance.\nThis \nwould\nappear\nas\nmultiple\nsmall\nopacities\nin\nthe\ncolon\non\nan\nX-ray,\nsimilar\nto\nwhat\nwe\nsee\nin\nthe\nimage. \n\u25cf\nHyperparathyroidism:\nWhile\nthis\ncondition\ncan\nresult\nin\nvarious\ngastrointestinal\nand\nbone\nmanifestations,\nit\ndoes\nnot\nproduce\nthe\ntype \nof\nradiographic\nappearance\ndepicted\nin\nthe\nimage. \n\u25cf\nIschemic\ncolitis:\nThis\nrefers\nto\ninflammation\nand\ninjury\nof\nthe\ncolon\ndue\nto\nreduced\nblood\nflow.\nWhile\nischemic\ncolitis\ncan\ncause \nchanges\nin\nthe\nappearance\nof\nthe\ncolon\non\nimaging,\nit\ndoesn't\ntypically\nmanifest\nas\nmultiple\nsmall\nopacities. \n\u25cf\nIngestion\nof\na\nheavy\nmetal:\nIngested\nheavy\nmetals,\nsuch\nas\nlead\nor\nbismuth,\ncan\nappear\nas\nradiopaque\nsubstances\nin\nthe \ngastrointestinal\nsystem.\nHowever,\nthe\npattern\nof\ndistribution\nand\nthe\nconsistency\nof\nthe\nopacities\nseen\nhere\nare\nmore\nsuggestive\nof \nresidual\nbarium\nfrom\nlaxatives\nrather\nthan\ningested\nheavy\nmetals. \nConclusion:\nBased\non\nthe\nradiographic\nappearance\nand\nthe\nprovided\noptions,\nthe\nmost\nlikely\ndiagnosis\naccounting\nfor\nthe\nfindings\non\nthis \nabdominal\nradiograph\nis\n'Chronic\nlaxative\nuse'.\nThis\npattern\nis\nsuggestive\nof\nthe\nretention\nof\nbarium,\na\nradiopaque\nsubstance\nused\nin\nsome \nlaxatives.\nFigure\n3.\nMultimodal\nReasoning\nExplanations\nProvided\nby\nGPT-4V.\nFour\nexample\ncases\nand\nGPT-4V\noutput \nfor\nGPT-4V\n(Image\nOnly),\nGPT-4V\n(Text\nOnly),\nMultimodal\nGPT-4V,\nand\nMultimodal\nGPT-4V\nwith\nCoT\n(chain\nof \nthought)\nare\nshown.\nMultimodal\nCoT\n(chain\nof\nthought)\nuses\nthe\nsame\nprompt\nbut\nadds\n\u201cLet\u2019s\nthink\nstep\nby\nstep\u201d \nto\nthe\nend\nof\nthe\nquestion\nto\nelicit\nreasoning.\nCorrect\nanswers\nare\nhighlighted\nin\ngreen\nand\nthe\nrespondent \ndistribution\nis\nalso\nshown.\nWe\nranked\ncases\nby\nhuman\nperformance\nand\nselected\nA-B.\nDifficult\nexamples\nthat \nillustrate\nGPT-4V\nreasoning\nmultimodally\nand\nfrom\ntext\nalone,\nas\nwell\nas\neasy\nexamples\nwhere\nC.\nGPT-4V \nanswers\nincorrectly\nand\nD.\nGPT-4V\n(Text\nOnly)\nrefuses\nto\nanswer\nwithout\nthe\nimage.\n24\n Figure\n4.\nMultimodal\nEvaluation\non\nClinicopathological\nConferences\nFigure\n4.\nMultimodal\nEvaluation\non\nClinicopathological\nConferences\n.\nShown\nare \nphysician-scored\nperformance\n(0\n=\nworst,\n5\n=\nbest)\nof\nMultimodal\nGPT-4V\nvs.\nGPT-4V\n(Text\nOnly)\non \n69\nNEJM\nclinicopathological\nconferences\n(CPCs)\nusing\nthe\ntext\n(+/-\nimages)\nin\nthe\n\u201cPresentation\nof \nCase\u201d\nsection\nof\nthe\nCPCs.\nEach\ncase\nwas\nscored\nby\na\nboard-certified\nphysician\nusing\nthe\nBond\net\nal. \nGen\nIntern\nMed\n.\n2012\ncriteria.\n25\n "}