{"url": "http://arxiv.org/pdf/2307.16850v1", "title": "Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare Insights: Evaluating Accuracy and Relevance in Patient and HCP Contexts", "text": "arXiv:2307.16850v1  [cs.CL]  24 Jul 2023COMPARATIVE ANALYSIS OF DRUG-GPT\u2122AND CHATGPT\nLLM S FOR HEALTHCARE INSIGHTS : EVALUATING ACCURACY\nAND RELEVANCE IN PATIENT AND HCP C ONTEXTS\nGiorgos Lysandrou\ngeorge@talkingmedicines.comRoma English Owen\nroma@talkingmedicines.comKirsty Mursec\nkirsty@talkingmedicines.com\nGrant Le Brun\ngrant@talkingmedicines.comElizabeth A. L. Fairley \u2217\nelizabeth@talkingmedicines.com\n\u2217corresponding author\nAugust 1, 2023\nABSTRACT\nThis study presents a comparative analysis of three Generat ive Pre-trained Transformer (GPT) so-\nlutions in a question and answer (Q&A) setting: Drug-GPT\u21223, Drug-GPT\u21224, and ChatGPT, in\nthe context of healthcare applications. The objective is to determine which model delivers the most\naccurate and relevant information in response to prompts re lated to patient experiences with atopic\ndermatitis (AD) and healthcare professional (HCP) discuss ions about diabetes. The results demon-\nstrate that while all three models are capable of generating relevant and accurate responses, Drug-\nGPT\u21223 and Drug-GPT\u21224, which are supported by curated datasets of patient and HCP social\nmedia and message board posts, provide more targeted and in- depth insights. ChatGPT, a more\ngeneral-purpose model, generates broader and more general responses, which may be valuable for\nreaders seeking a high-level understanding of the topics bu t may lack the depth and personal insights\nfound in the answers generated by the specialized Drug-GPT\u2122models. This comparative analysis\nhighlights the importance of considering the language mode l\u2019s perspective, depth of knowledge, and\ncurrency when evaluating the usefulness of generated infor mation in healthcare applications.\nKeywords Drug-GPT\u2122\u00b7ChatGPT \u00b7GPT\u00b7healthcare \u00b7insights\u00b7patients\u00b7healthcare professionals \u00b7large language\nmodels\u00b7natural language processing \u00b7linguistics\nIntroduction\nGenerative Pre-trained Transformers (GPTs) are state-of- the-art large language models (LLMs) that have garnered\nsigni\ufb01cant attention in recent years, particularly with th e introduction of ChatGPT, due to their ability to generate\nhuman-like text. These models have demonstrated great pote ntial in various natural language processing (NLP) tasks,\nsuch as text classi\ufb01cation, question answering and summari sation, making them highly relevant for applications acros s\ndiverse domains, including healthcare.\nHealthcare companies have acknowledged the enormous poten tial of LLMs in revolutionizing their operations. By\nharnessing the capabilities of LLMs, these organizations c an extract valuable insights, enhance decision-making pro -\ncesses, and ultimately improve patient outcomes. Some nota ble applications of LLMs in healthcare include:\n\u2022 SUPPORTING CLINICAL DECISION MAKING : LLMs can examine extensive medical literature and clinica l\nguidelines to offer evidence-based recommendations for HC Ps, aiding in diagnosis, treatment planning, and\npersonalized care [1]. APREPRINT - AUGUST 1, 2023\n\u2022 FACILITATING DRUG DISCOVERY AND DEVELOPMENT : LLMs contribute to the identi\ufb01cation of patterns\nand potential drug candidates by analysing molecular data, scienti\ufb01c literature, and clinical trials. This expe-\ndites the drug discovery process and empowers researchers t o make well-informed choices [2].\n\u2022 A IDING MEDICAL TRANSLATION : LLM\u2019s can enable translation that aids in effective commun ication be-\ntween healthcare providers and patients. Leveraging advan ced language processing capabilities, LLM\u2019s can\nboth swiftly and precisely translate medical and technical terminology into everyday language. This can help\npatients\u2019 understanding of their diagnosis and treatment o ptions [3].\nIn this comparative analysis, we evaluate the performance o f three GPT solutions in a question and answer (Q&A)\nsetting: Drug-GPT\u21223 and Drug-GPT\u21224, which are based on GPT-3 and GPT-4 respectively, and suppo rted by\ncurated datasets of patient and HCP social media and message board posts, and ChatGPT, a more general-purpose\nmodel, to assess their performance in the healthcare domain . Our objective is to determine which model delivers\nthe most accurate and relevant information, demonstrated b y responses to prompts related to patient experiences with\nAD and HCP discussions about diabetes. By comparing the capa bilities of these models, we aim to highlight their\nstrengths and limitations and provide insights into their p otential applications in healthcare.\nBackground\nLi et al. (2023) conducted a systematic review of existing pu blications on the use of ChatGPT in healthcare, aiming\nto provide insights into the current state of ChatGPT in medi cal applications for general readers, HCPs, and NLP\nscientists. The authors found that the current release of Ch atGPT has achieved only moderate performance in various\ntests and is unreliable for actual clinical deployment, as i t is not designed for clinical applications. They concluded\nthat specialized NLP models trained on biomedical datasets still represent the right direction for critical clinical a p-\nplications. While this work highlights the importance of ut ilising specialised data, our approach opts to include this\ndata through prompt engineering instead of training, which has the bene\ufb01ts of retaining the LLM\u2019s general natural lan-\nguage generation abilities, while still delivering specia lised insights on real-world patient and HCP experiences. T he\nreview also discusses ethical concerns and potential pitfa lls of using ChatGPT in healthcare, emphasizing the need for\ncreators and providers of chatbots like ChatGPT to address t hese issues to avoid catastrophic consequences [4].\nSalvagno et al. (2023) discuss the potential use of arti\ufb01cia l intelligence (AI) chatbots, speci\ufb01cally ChatGPT, in sci-\nenti\ufb01c writing. The authors suggest that ChatGPT can assist researchers in organizing material, generating initial\ndrafts, and proofreading. However, they emphasize that AI- generated work should not replace human judgment and\nshould always be reviewed by experts, which is why Drug-GPT\u2122is aimed at providing healthcare insights to aid, not\nreplace, human decision-making. The paper also raises ethi cal concerns, such as the risk of plagiarism, inaccuracies,\nand potential imbalances in accessibility between high and low-income countries due to costs [5].\nCascella et al. (2023) explored the potential applications and limitations of ChatGPT, in healthcare. Although Chat-\nGPT has shown promising results in various NLP tasks and even successfully passed the United States Medical Li-\ncensing Exam (USMLE), its performance in real-world clinic al scenarios remains uncertain. The authors investigated\nthe feasibility of ChatGPT in four clinical and research sce narios: supporting clinical practice, scienti\ufb01c producti on,\npotential misuse in medicine and research, and reasoning ab out public health topics. While ChatGPT demonstrated\nan ability to generate coherent and realistic text, the stud y highlights the importance of recognizing and promoting\neducation on the appropriate use and potential pitfalls of A I-based LLMs in medicine, such as \"hallucinated\" answers,\na behaviour we take cautious measures to avoid with Drug-GPT\u2122. Additionally, ethical concerns surrounding the use\nof ChatGPT in scienti\ufb01c articles warrant further attention [6].\nIn a study conducted by Johnson et al. (2023), the authors ass essed the accuracy and reliability of ChatGPT-generated\nmedical responses. The study involved 33 physicians across 17 specialities, generating 284 medical questions. These\nquestions were then answered by ChatGPT, and the physicians graded the responses for accuracy and completeness\nusing speci\ufb01ed Likert scales. The results demonstrated tha t ChatGPT generated largely accurate information for\ndiverse medical queries as judged by academic physician spe cialists, with a median accuracy score of 5.5 (between\nalmost completely and completely correct) and mean score of 4.8 (between mostly and almost completely correct).\nHowever, important limitations were also identi\ufb01ed, indic ating the need for further research and model development\nto correct inaccuracies and ensure validation. This study p rovides an early evidence base for the potential of AI-based\nsystems like ChatGPT, or even more specialised healthcare s olutions such as Drug-GPT\u2122, in providing accurate and\ncomprehensive medical information, while also emphasizin g the need for cautious implementation in medical practice\nand research [7].\nWang et al. (2023) introduce ClinicalGPT, an LLM speci\ufb01call y designed and optimized for clinical scenarios. Recog-\nnizing the limitations of existing LLMs in medical applicat ions, the authors leverage extensive and diverse real-worl d\n2 APREPRINT - AUGUST 1, 2023\ndata, including medical records, domain-speci\ufb01c knowledg e, and multi-round dialogue consultations, to train Clin-\nicalGPT. A comprehensive reinforcement learning evaluati on framework is also introduced, encompassing medical\nknowledge question-answering, medical exams, patient con sultations, and diagnostic analysis of medical records. Th e\nresults reveal that ClinicalGPT signi\ufb01cantly outperforms other models in these tasks, demonstrating the effectivene ss\nof their approach in adapting LLMs to the critical domain of h ealthcare. This study underscores the importance of\nincorporating domain-speci\ufb01c knowledge and diverse data s ources, like the approach we took with Drug-GPT\u2122and\nits specialised curated patient and HCP dataset, to enhance the utility of LLMs in specialized \ufb01elds such as medicine\n[8].\nMethodology\nThe focus of these experiment comparisons is on GPT language models, developed by OpenAI, leveraging unsuper-\nvised learning and large-scale pre-training to generate hu man-like text by predicting the next word in a sentence given\nits context. The \ufb01rst GPT model, GPT-1 [9], laid the foundati on for its successors, followed by GPT-2 [10], GPT-3\n[11] and GPT-4 [12], which offer increasingly sophisticate d linguistic capabilities. GPT-3 was a big breakthrough in\nperformance, and hence it was released to the public as part o f a chat system called ChatGPT.\nChatGPT, a chatbot application initially backed by GPT-3, w as designed speci\ufb01cally for generating contextually rel-\nevant and meaningful responses in a conversational setting . While it shares the core architecture and pre-training\napproach with GPT-3, ChatGPT incorporates essential modi\ufb01 cations to GPT-3 to better cater to the unique require-\nments of chatbot applications. To enhance its conversation al capabilities, GPT-3 is \ufb01ne-tuned on custom datasets that\ncontain conversational data, enabling it to learn the nuanc es of human dialogue and generate context-aware responses,\nresulting in ChatGPT. Additionally, the model is subjected to Reinforcement Learning from Human Feedback (RLHF)\nto iteratively improve its performance by learning from use r interactions. This allows ChatGPT to stand out from\ntraditional GPT models, providing a more effective solutio n for generating human-like responses in conversational AI\napplications.\nDrug-GPT\u2122is an advanced and specialized proprietary tool not availab le for public use, unlike ChatGPT, aimed at\noffering valuable insights regarding patients and HCPs, in a Q&A setting. Based on empirical research evidence\ndemonstrating that specialized LLMs outperform general on es in speci\ufb01c domains like healthcare [4][7][8], we have\nopted for the approach of utilizing a specialized LLM soluti on to ensure better accuracy and reliability in our targeted\napplication. This solution utilizes a carefully curated pa tient and HCP dataset derived from social media and message\nboard posts, a sophisticated information retrieval system , and the GPT-3 or GPT-4 LLMs. Owing to the distinct\nLLMs supporting Drug-GPT\u21223 and Drug-GPT\u21224, the latter is capable of accommodating a larger input, hen ce\nconsidering a larger context from its knowledge base before generating a response. By implementing speci\ufb01cally\ntailored hyperparameters and prompt engineering, Drug-GP T\u2122delivers reproducible responses based on the most\nrelevant content within its knowledge base dataset. The pro vided answers are factual, stemming from real-world\nexperiences of patients and HCPs, rather than being derived from the LLM\u2019s own knowledge. Consequently, Drug-\nGPT\u2122\u2019s knowledge encompasses a broader scope compared to GPT-3, GPT-4, or ChatGPT.\nThe comparison is based on the Q&A answers provided by Drug-G PT\u21223, Drug-GPT\u21224 and ChatGPT in response\nto the following prompts:\n1. Experiment 1: P ATIENTS : \u201cWhat are three challenges of living with atopic dermatiti s?\u201d.\n2. Experiment 2: HCP S: \u201cWhat are the top themes HCPs are talking about in relation t o diabetes?\u201d.\nThe choice of hyperparameters plays a crucial role in obtain ing reproducible outcomes. For this purpose, we set\nthe Temperature parameter to 0, thereby ensuring that the mo del generates the most con\ufb01dent answers without any\nrandomness. Moreover, we set the Top P parameter to 1, which e nables the model to select the most probable words\nduring the token sampling process. This approach facilitat es a deterministic and consistent output for a given questio n.\nThese selection criteria not only enhance the overall coher ence and accuracy of the generated text, through avoiding\nrandom, diverse and less probable responses, but also provi de a reliable basis for evaluating the models\u2019 ef\ufb01cacy in\nthe context of the given tasks, because the generated respon se is always the most probable.\nThe experiments were conducted using the hyperparameters s peci\ufb01ed in Table 1. The hyperparameters of the general-\nuse ChatGPT were not made publicly available by OpenAI, but t he version of ChatGPT that produced our results is\nthe February 13th 2023 release. The results are analysed in t erms of relevance and accuracy.\n3 APREPRINT - AUGUST 1, 2023\nName ChatGPT GPT-3 GPT-4\nModel name - text-davinci-003 gpt-4 8k\nVersion Feb 13 2023 release 2022-12-01 release 2023-03-15- preview\nMax tokens - 512 2048\nTemperature - 0 0\nTop P - 1 1\nFrequency penalty - 0 0\nPresence penalty - 0 0\nTable 1: Experiment General Pre-trained Transformer Large Language Models hyperparameters detailed setup.\nExperiments\nIn these experiments, the models were given a prompt, with th e models\u2019 responses being analysed to determine their\naccuracy, relevance, and conciseness. The goal was to ident ify any commonalities in the responses and assess the\ndepth and quality of information provided by each solution.\nExperiment 1: Patients\nThe comparison is based on the answers provided by Drug-GPT\u21223, Drug-GPT\u21224, and ChatGPT in response to the\nfollowing prompt:\n\"What are three challenges of living with atopic dermatitis ?\"\nWhat the question asks for can be answered the best by \ufb01rst-ha nd experience of patients experiencing AD. While\nChatGPT only has access to the general data it was pre-traine d and \ufb01ne-tuned with, Drug-GPT\u21223 and 4 have access\nto a curated patient dataset, with patients speci\ufb01cally exp eriencing AD. Based on the question, Drug-GPT\u21223 and 4\ncan provide an answer by retrieving the most relevant patien t experiences, talking expressly about challenges of livin g\nwith AD.\nExperiment 2: HCPs\nThe comparison is based on the answers provided by Drug-GPT\u21223, Drug-GPT\u21224, and ChatGPT in response to the\nfollowing prompt:\n\"What are the top themes HCPs are talking about in relation to Diabetes? Provide the answer as a list highlighting\nthe context with a quote from the context.\"\nThe question asks for information around HCP discussions ab out diabetes, which can be best answered with real-world\nHCP discussions in this domain. ChatGPT again only has acces s to the general information found in its pre-training\nand \ufb01ne-tuning data, while Drug-GPT\u21223 and 4 have access to a curated HCP dataset, of online HCP inte ractions.\nDrug-GPT\u21223 and 4 based their answer on the retrieved conversations aro und diabetes.\nResults\nThe complete prompts for the questions and answers provided by the LLMs in the following experiments, can be seen\nin the appendix section Prompts & Answers.\nExperiment 1: Patients\nAll three models provided answers that highlighted the chal lenges of living with AD. The full prompt questions and\nanswers can be seen in section \"Experiment 1: Patients\", in \" Prompts & Answers\" in the appendix. A summary of\neach model\u2019s response is as follows:\n1. Drug-GPT\u21223:\n(a) Damage caused by long-term use of topical steroids.\n(b) Overwhelming nature of \ufb01nding symptom solutions.\n4 APREPRINT - AUGUST 1, 2023\n(c) Dif\ufb01culties managing food allergies and sensitivities .\n2. Drug-GPT\u21224:\n(a) Damage from long-term use of topical steroids.\n(b) Identifying and managing food triggers and allergies.\n(c) Finding effective treatments and managing \ufb02are-ups.\n3. ChatGPT:\n(a) Skin irritation and discomfort.\n(b) Social isolation and psychological impact.\n(c) Treatment dif\ufb01culties.\nAll three models agreed that \ufb01nding treatment options for AD is a challenge. ChatGPT provided a longer but still\nrelevant response, which included an introduction to the he alth condition. The responses from Drug-GPT\u21223 and\nDrug-GPT\u21224 were more concise but still relevant. All three models coul d identify signi\ufb01cant challenges faced by\nindividuals with AD, with ChatGPT providing a more verbose a nswer. Drug-GPT\u21223 and Drug-GPT\u21224\u2019s answers\nfocus on speci\ufb01c aspects, such as the damage caused by prescr ibed topical steroids and the dif\ufb01culty in managing food\ntriggers and allergies. These answers demonstrate a more ta rgeted approach and seem to address issues that might be\nfaced by patients in their treatment process.\nThe answer provided by ChatGPT, is more general and could be p erceived as coming from someone who does not\nhave \ufb01rst-hand experience with the condition but possesses knowledge about it. The response outlines three broader\nchallenges: skin irritation and discomfort, social isolat ion and psychological impact, and treatment dif\ufb01culties. T he\nanswer provides a topline overview of the condition, which m ay be valuable for readers looking for a general under-\nstanding of AD. However, this general approach might lack th e depth and personal insights that could be found in\nanswers generated by models with a more focused, \ufb01rst-hand u nderstanding of the condition and its treatments.\nDrug-GPT\u2122\u2019s responses were noticeably more informal and accessible t o laypeople in nature. Accessing patient ex-\nperiences expressed in the way patients themselves discuss them is of utmost importance for the industry to improve\ncomprehension and address the issues patients face. This di stinction is attributed to Drug-GPT\u2122\u2019s restriction of gen-\neration of answers from a curated collection of patient soci al media posts, contrasting with the broader range of data\nsources that ChatGPT was trained on. Overall, the compariso n highlights the importance of considering the language\nmodel\u2019s perspective, the information it considers in order to generate a response, and depth of knowledge in assessing\nthe usefulness of generated information.\nExperiment 2: HCPs\nAll three models provided answers that highlighted the top t hemes discussed by HCPs in relation to diabetes. The full\nprompt questions and answers can be seen in section \"Experim ent 2: HCPs\", in \"Prompts & Answers\" in the appendix.\nA summary of each model\u2019s response is as follows:\n1. Drug-GPT\u21223:\n(a) Sustained diabetes control with thiazolidinediones (T ZD).\n(b) Prevention of progression from prediabetes to diabetes with acarbose.\n(c) Adjusting diabetes regimens for better control.\n(d) Various drug treatments for diabetes and related condit ions.\n(e) Risk of pancreatitis with certain diabetes drugs.\n(f) First line treatment for type 1 diabetes: multiple daily injections or continuous insulin infusion.\n(g) Postprandial hypoglycemia and potential causes.\n(h) Complications of diabetes medications.\n(i) Explanation of type 1 diabetes: autoimmune attack on ins ulin-producing cells.\n(j) Misdiagnosis of diabetes and its rarity.\n2. Drug-GPT\u21224:\n(a) Diabetes control and A1c improvement with thiazolidine diones (TZD).\n(b) Medications for diabetes: metformin and empagli\ufb02ozin.\n(c) Acarbose lowers progression from prediabetes to diabet es.\n(d) Adjusting diabetes regimen through primary care doctor .\n5 APREPRINT - AUGUST 1, 2023\n(e) Treatment for type 1 diabetes: prandial and basal insuli n or continuous subcutaneous insulin infusion.\n(f) Postprandial hypoglycemia due to increased insulin sen sitivity.\n(g) Misdiagnosis of diabetes and its potential causes.\n3. ChatGPT:\n(a) Prevention of diabetes.\n(b) Treatment options for diabetes.\n(c) Individualized care for diabetic patients.\n(d) Lifestyle modi\ufb01cations in diabetes management.\n(e) Technology in diabetes care and management.\nDrug-GPT\u21223 and Drug-GPT\u21224 provided relevant themes, with both of them including quot es for each theme. Chat-\nGPT provided a list with \ufb01ve themes and accompanying quotes, which were accurate and relevant. The results showed\nthat all three models were able to capture the top themes in di abetes-related discussions among HCPs. Drug-GPT\u21223\u2019s\nanswer includes quotes from various sources, addressing sp eci\ufb01c themes such as disease progression prevention, drug\nside effects and risks, and disease misdiagnosis. Drug-GPT\u21224\u2019s response, is another comprehensive list of similar,\nequally speci\ufb01c themes and context. Both of these answers se em to be more focused on the medical aspects of diabetes\nand its complications.\nChatGPT\u2019s answer appears to be more general and could be perc eived as coming from someone who is not themselves\nan HCP, but has a basic understanding of the topic. The respon se provides a list of themes along with quotes from\nthe context, covering aspects such as prevention, treatmen t options, individualized care, lifestyle modi\ufb01cations, a nd\ntechnology. With respect to currency, it is important to not e that ChatGPT\u2019s answers are outdated by 2 or 3 years,\nas seen in the publication dates provided alongside its sour ces, which may affect the relevance and accuracy of the\ninformation provided. While the answer offers a broad overv iew of the themes discussed by HCPs, it may lack the\ndepth, speci\ufb01city, and up-to-date knowledge that could be f ound in answers generated by models with a more focused\nunderstanding of the medical aspects of diabetes.\nWhen comparing the answers provided by ChatGPT and Drug-GPT\u2122, it was evident that Drug-GPT\u2122\u2019s responses\nexhibited a signi\ufb01cantly higher similarity to the content a nd level of detail found in patient support materials and\nprescribing information commonly used within the industry [13]. This comparison also highlights the importance of\nconsidering the language model\u2019s perspective, the informa tion it considers in order to generate a response, depth of\nknowledge, and currency of the response when evaluating the usefulness of the generated information.\nDiscussion\nThe comparative analysis of GPT language models in this stud y revealed that specialized models like Drug-GPT\u2122\n3 and Drug-GPT\u21224, which leverage curated datasets of patient and HCP experi ences, demonstrate a more focused\napproach in generating accurate and contextually relevant insights. In contrast, ChatGPT, a general-purpose model,\nwas able to provide coherent and factually correct response s, but could lack the depth and speci\ufb01city offered by the\nspecialized models.\nIn Experiment 1, Drug-GPT\u21223 and Drug-GPT\u21224 can provide more targeted and speci\ufb01c answers, in part to th eir\naccess to curated patient datasets. They were able to identi fy challenges faced by individuals with AD, focusing on\naspects such as the damage caused by prescribed topical ster oids and the dif\ufb01culty in managing food triggers and\nallergies. ChatGPT, on the other hand, provided a more gener al response that, while still relevant, may lack the\ndepth and personal insights that could be found in the answer s generated by models with a more focused, \ufb01rst-hand\nunderstanding of the condition and its treatments.\nIn Experiment 2, Drug-GPT\u21223 and Drug-GPT\u21224 again demonstrated more focused understanding, providin g rele-\nvant themes supported by quotes for context for each theme. C hatGPT\u2019s answer was more general, covering broader\nthemes such as prevention, treatment options, individuali zed care, lifestyle modi\ufb01cations, and technology. However ,\nChatGPT\u2019s answers were outdated by 2 or 3 years, which may aff ect the relevance and accuracy of the information\nprovided.\nThe experiments showcased the ability of Drug-GPT\u21223 and Drug-GPT\u21224 to retrieve real-world experiences and\ninsights from patients and HCPs, illustrating their potent ial in delivering more targeted and valuable information. T he\nanswers generated by these specialized models were concise , relevant, and encompassed a broader scope of knowledge\ncompared to ChatGPT.\nWhile ChatGPT provided comprehensive and general answers, its responses lacked the \ufb01rst-hand experiences and\ninsights that are central to understanding the nuances of th e conditions and treatments discussed. Moreover, the\n6 APREPRINT - AUGUST 1, 2023\nresponses generated by ChatGPT appeared to be slightly outd ated, which might affect the relevance of the information\nprovided. This observation emphasizes the importance of us ing specialized models in domain-speci\ufb01c applications, as\nthey can provide more up-to-date, accurate, and contextual ly rich information.\nIn both experiments, the choice of hyperparameters played a crucial role in obtaining consistent and reproducible\noutcomes. The deterministic approach adopted by setting th e Temperature parameter to 0 and the Top P parameter\nto 1 ensured the generation of coherent and accurate text whi le providing a reliable basis for evaluating the models\u2019\nef\ufb01cacy. In comparison, with the Temperature parameter set to anything above 0 and Top P set to anything below 1,\nwe sacri\ufb01ce repeatability and accuracy for creativity, whi ch increases the risk of \"hallucinated\" answers [14].\nThe results of this study indicate that specialized models l ike Drug-GPT\u21223 and Drug-GPT\u21224 have clear distinctions\nover general-purpose models like ChatGPT when addressing s peci\ufb01c domain-related questions. Their focus on cu-\nrated datasets, prompt engineering, and tailored hyperpar ameters enable them to deliver more accurate, reliable, and\ncontextually relevant information. However, it is crucial to consider the language model\u2019s perspective, the informat ion\nit considers in order to generate a response, depth of knowle dge, and currency of the response when evaluating the\nusefulness of the generated information.\nConclusion\nIn this comparative analysis, we evaluated the performance of three GPT solutions in a Q&A setting: Drug-GPT\u2122\n3, Drug-GPT\u21224, and ChatGPT, in the context of healthcare applications. O ur experiments focused on assessing the\nmodels\u2019 ability to provide accurate and relevant informati on in response to prompts related to patient experiences wit h\nAD and HCP discussions about diabetes.\nThe results demonstrated that all three models were capable of generating relevant and accurate responses. However,\nDrug-GPT\u21223 and Drug-GPT\u21224, which were supported by a curated dataset of patient and HC P social media and\nmessage boards posts, provided more targeted and in-depth i nsights into the speci\ufb01c challenges faced by patients\nand the themes discussed by HCPs. ChatGPT, a more general-pu rpose model, generated broader and more general\nresponses, which may be valuable for readers seeking a high- level understanding of the topics but may lack the depth\nand personal insights found in the answers generated by the s pecialized Drug-GPT\u2122models.\nAdditionally, it is essential to address potential halluci nations of answers and ensure responsible use of these AI too ls.\nEthical concerns and potential dangers associated with AI- generated information should not be overlooked. Ensuring\nthat AI-generated content is reviewed by experts and does no t replace human judgment is crucial for responsible\nimplementation in medical practice and research.\nThis comparative analysis highlights the importance of con sidering the language model\u2019s perspective, depth of knowl-\nedge, and currency when evaluating the usefulness of genera ted information in healthcare applications. While general -\npurpose models like ChatGPT can provide valuable insights, specialized models like Drug-GPT\u21223 and Drug-GPT\u2122\n4, which are supported by domain-speci\ufb01c datasets, offer a m ore focused understanding of the medical aspects and\nreal-world experiences of patients and HCPs. This distinct ion is crucial for healthcare organizations seeking to harn ess\nthe potential of LLMs to improve patient care, enhance decis ion-making processes, and revolutionize their operations .\nReferences\n[1] Arya Rao, John Kim, Meghana Kamineni, Michael Pang, Wins ton Lie, and Marc D Succi. Evaluating chatgpt as\nan adjunct for radiologic decision-making. medRxiv , pages 2023\u201302, 2023.\n[2] Gaurav Sharma and Abhishek Thakur. Chatgpt in drug disco very. 2023.\n[3] Bernard Marr. Revolutionizing healthcare: The top 14 us es of chatgpt in medicine and wellness, Mar 2023.\n[4] Jianning Li, Amin Dada, Jens Kleesiek, and Jan Egger. Cha tgpt in healthcare: A taxonomy and systematic\nreview. medRxiv , pages 2023\u201303, 2023.\n[5] Michele Salvagno, Fabio Silvio Taccone, Alberto Giovan ni Gerli, et al. Can arti\ufb01cial intelligence help for\nscienti\ufb01c writing? Critical care , 27(1):1\u20135, 2023.\n[6] Marco Cascella, Jonathan Montomoli, Valentina Bellini , and Elena Bignami. Evaluating the feasibility of chatgpt\nin healthcare: an analysis of multiple clinical and researc h scenarios. Journal of Medical Systems , 47(1):33, 2023.\n[7] Douglas Johnson, Rachel Goodman, J Patrinely, Cosby Sto ne, Eli Zimmerman, Rebecca Donald, Sam Chang,\nSean Berkowitz, Avni Finn, Eiman Jahangir, et al. Assessing the accuracy and reliability of ai-generated medical\nresponses: an evaluation of the chat-gpt model. 2023.\n7 APREPRINT - AUGUST 1, 2023\n[8] Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, and Xiaohu Li. Clinicalgpt: Large language models\n\ufb01netuned with diverse medical data and comprehensive evalu ation. arXiv preprint arXiv:2306.09968 , 2023.\n[9] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Su tskever, et al. Improving language understanding by\ngenerative pre-training. 2018.\n[10] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dari o Amodei, Ilya Sutskever, et al. Language models are\nunsupervised multitask learners. OpenAI blog , 1(8):9, 2019.\n[11] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al . Language models are few-shot learners. Advances\nin neural information processing systems , 33:1877\u20131901, 2020.\n[12] OpenAI. Gpt-4 technical report, 2023.\n[13] FDA Center for Drug Evaluation and Research. Generic dr ug patient education.\n[14] Gernot Beutel, Eline Geerits, and Jan T Kielstein. Arti \ufb01cial hallucination: Gpt on lsd? Critical Care , 27(1):148,\n2023.\nAuthor details\nTalking Medicines Limited, SC447227\n25 Blythswood Square, Top Floor, G2 4BL, Glasgow, Scotland, UK\nAcknowledgements\nWe would like to express our gratitude to Beatrice Alex, Lewi s Boyd, and Ellen Halliday, as well as the Talking\nMedicines Founders Jo-Anne Halliday, Scott F. Crae and Eliz abeth A.L. Fairley for all of their support of this publica-\ntion.\nPrompts & Answers\nExperiment 1: Patients\nPrompt question:\nWhat are 3 challenges of living with atopic dermatitis?\nDrug-GPT\u21223 answer:\n1. Damage caused by decades of prescribed topical steroids.\n2. Finding solutions for symptoms can be overwhelming.\n3. Food allergies and sensitivities can be difficult to mana ge.\nDrug-GPT\u21224 answer:\n1. Damage caused by long-term use of prescribed topical ster oids.\n2. Identifying and managing food triggers and allergies tha t can exacerbate the condition.\n3. Finding effective treatments and managing flare-ups, wh ich can be overwhelming and frustrating.\nChatGPT answer:\nAtopic dermatitis (AD), also known as eczema, is a chronic in flammatory skin condition that affects\nmillions of people worldwide. Some of the challenges of livi ng with atopic dermatitis include:\n1. Skin irritation and discomfort: People with atopic derma titis experience persistent itching,\ndryness, and redness on their skin. These symptoms can cause discomfort and even pain, which\ncan be distracting and affect their daily activities and qua lity of life.\n2. Social isolation and psychological impact: Atopic derma titis can be visibly noticeable and often\nleads to social stigma and embarrassment, especially in mor e severe cases. As a result, people\nwith AD may avoid social activities, feel self-conscious ab out their appearance, and even\nexperience depression and anxiety.\n8 APREPRINT - AUGUST 1, 2023\n3. Treatment difficulties: While there are various treatme nt options available for atopic\ndermatitis, finding the right treatment can be challenging . Some treatments may cause side\neffects or not work for everyone, and managing the condition can require a lot of time and\neffort, which can be frustrating and exhausting for some ind ividuals.\nExperiment 2: HCPs\nPrompt question:\nWhat are the top themes HCPs are talking about in relation to D iabetes? Provide the answer as a\nlist highlighting the context with a quote from the context.\nDrug-GPT\u21223 answer:\n1. Diabetes control that is sustained - \"Excellent diabetes control that is sustained.\nDepending on the population we\u2019re talking about, typical A1 c improvement with a TZD can be\nup to 1.5%. This is comparable to metformin and GLP1a, signif icantly more than most of the\nother new drugs. It is also comparable to SUs - but the differe nce there is it is *\nsustained*.\"\n2. Prevention of progression from prediabetes to diabetes - \"There\u2019s OK evidence with acarbose\nlowering progression to diabetes - it lowers it by about 20-2 5%, but the problem is that\nalmost no one can tolerate acarbose without severe bloating and flatulence. But there\u2019s\nabsolutely zero evidence that glipizide will prevent progr ession from prediabetes to\ndiabetes.\"\n3. Adjusting diabetes regimens - \"I\u2019m not necessarily secon d-guessing a provider who has his\ncomplete history, but it might be worth talking to his primar y care doctor to see if his\ndiabetes regimen needs to be adjusted. Especially consider ing that his diabetes is not well-\ncontrolled based on his A1C. Also looks like he might have bor derline iron deficiency..\"\n4. Drug treatments for diabetes - \"to group them: diabetes: & gt;metformin &gt;empagliflozin\nblood pressure, kidney protection: &gt;ramipiril blood th inner, typically used for heart\nattack/stroke prevention in someone at particularly high r isk (who has had an event before),\nsuch as someone with a prior history of tia &gt;clopidogrel p rostate enlargement: &gt;\ntadalafil ...\"\n5. Risk of pancreatitis with certain drugs - \"Liraglutide, s emaglutide, dulaglutide can be used\nat any egfr. The DPP4i have variable metabolism. Linaglipti n doesn\u2019t need any dose\nadjustment for renal excretion for example. They do probabl y increase the risk of\npancreatitis. Other notable risk includes angioedema.\"\n6. First line treatment for type 1 diabetes - \"Here is the sect ion on 1st line treatment copied\ndirectly from the guideline you linked to me: \"Most people wi th type 1 diabetes should be\ntreated with multiple daily injections of prandial and basa l insulin, or continuous\nsubcutaneous insulin infusion.\"\"\n7. Postprandial hypoglycemia - \"Your body could just be more sensitive to glucose in your body,\nso when it sees a sugar load from a meal it may secrete more insu lin than normal. There\nare other issues that can cause postprandial hypoglycemia ( like after bariatric surgery,\nsome autoimmune diseases, etc) but from what knowledge I hav e, it sounds like you don\u2019t\nhave any of these.\"\n8. Complications of diabetes medications - \"In the context o f something like diabetes, this can\nbe extra complicated because your body is responding to a lot of different signals, and\nthat is complicated further when you\u2019re on a blood sugar lowe ring medication.\"\n9. Explanation of type 1 diabetes - \"Type 1 diabetes is a disea se where your body attacks the\ncells in the pancreas that produce a hormone called insulin. Insulin\u2019s function in the body\nis to regulate the uptake of glucose into the cells. Glucose i s a simple sugar, and is the\nmain source of energy for the body. Without insulin, no gluco se can be used by the body.\"\n10. Misdiagnosis of diabetes - \"There are people who truly ar e misdiagnosed - a single a1c 6.5\nand never again, and someone coded them as DM, or someone who r equested a refill of\nmetformin for their PCOS and a covering provider associated it with DM, etc. but those are\nvery few and far between.\"\nDrug-GPT\u21224 answer:\n1. Diabetes control and A1c improvement: \"Depending on the p opulation we\u2019re talking about,\ntypical A1c improvement with a TZD can be up to 1.5%.\"\n9 APREPRINT - AUGUST 1, 2023\n2. Medications for diabetes: \"diabetes: &gt;metformin &gt ;empagliflozin\"\n3. Progression from prediabetes to diabetes: \"There\u2019s OK ev idence with acarbose lowering\nprogression to diabetes - it lowers it by about 20-25%\"\n4. Adjusting diabetes regimen: \"it might be worth talking to his primary care doctor to see if\nhis diabetes regimen needs to be adjusted.\"\n5. Treatment for type 1 diabetes: \"Most people with type 1 dia betes should be treated with\nmultiple daily injections of prandial and basal insulin, or continuous subcutaneous insulin\ninfusion.\"\n6. Postprandial hypoglycemia: \"Your body could just be more sensitive to glucose in your body,\nso when it sees a sugar load from a meal it may secrete more insu lin than normal.\"\n7. Misdiagnosis of diabetes: \"There are people who truly are misdiagnosed - a single a1c 6.5\nand never again, and someone coded them as DM, or someone who r equested a refill of\nmetformin for their PCOS and a covering provider associated it with DM, etc.\"\nChatGPT answer:\nSure, here\u2019s a list of the top themes that HCPs are talking abo ut in relation to diabetes, along\nwith a quote from the context to support each theme:\nPrevention: \"Prevention is key, and I think that\u2019s where we n eed to go with diabetes. I think we\nneed to focus on prevention.\" (Source: Medscape Education D iabetes Patient Management:\nContinuous Glucose Monitoring and Insulin Management in Di abetes Management, Published June\n2020)\nTreatment options: \"There are many different classes of dia betes medications available, and it\u2019s\nimportant to choose the right one for each patient based on th eir individual needs and\npreferences.\" (Source: American Diabetes Association Sta ndards of Medical Care in Diabetes\n-2021, Published January 2021)\nIndividualized care: \"Individualizing treatment regimen s and empowering patients to self-manage\ntheir diabetes are critical for achieving optimal outcomes .\" (Source: American Diabetes\nAssociation Standards of Medical Care in Diabetes 2021, Pub lished January 2021)\nLifestyle modifications: \"Healthy lifestyle modificatio ns, including diet and exercise, are\nimportant components of diabetes management and should be e mphasized to all patients.\" (Source:\nAmerican Diabetes Association Standards of Medical Care in Diabetes -2021, Published January\n2021)\nTechnology: \"Technology, such as continuous glucose monit oring and insulin pumps, can help patients\nwith diabetes achieve better glycemic control and improve t heir quality of life.\" (Source:\nAmerican Diabetes Association Standards of Medical Care in Diabetes -2021, Published January\n2021)\n10 "}